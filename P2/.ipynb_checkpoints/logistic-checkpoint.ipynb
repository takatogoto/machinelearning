{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logstic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#######################################################################\n",
    "# Replace TODO with your code\n",
    "#######################################################################\n",
    "\n",
    "def binary_train(X, y, w0=None, b0=None, step_size=0.5, max_iterations=1000):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    - X: training features, a N-by-D numpy array, where N is the \n",
    "    number of training points and D is the dimensionality of features\n",
    "    - y: binary training labels, a N dimensional numpy array where \n",
    "    N is the number of training points, indicating the labels of \n",
    "    training data\n",
    "    - step_size: step size (learning rate)\n",
    "    - max_iterations: number of iterations to perform gradient descent\n",
    "\n",
    "    Returns:\n",
    "    - w: D-dimensional vector, a numpy array which is the weight \n",
    "    vector of logistic regression\n",
    "    - b: scalar, which is the bias of logistic regression\n",
    "\n",
    "    Find the optimal parameters w and b for inputs X and y.\n",
    "    Use the *average* of the gradients for all training examples\n",
    "    multiplied by the step_size to update parameters.\n",
    "    \"\"\"\n",
    "    N, D = X.shape\n",
    "    assert len(np.unique(y)) == 2\n",
    "\n",
    "\n",
    "    w = np.zeros(D)\n",
    "    if w0 is not None:\n",
    "        w = w0\n",
    "    \n",
    "    b = 0\n",
    "    if b0 is not None:\n",
    "        b = b0\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    TODO: add your code here\n",
    "    \"\"\"\n",
    "\n",
    "    assert w.shape == (D,)\n",
    "    return w, b\n",
    "\n",
    "\n",
    "def binary_predict(X, w, b):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    - X: testing features, a N-by-D numpy array, where N is the \n",
    "    number of training points and D is the dimensionality of features\n",
    "    \n",
    "    Returns:\n",
    "    - preds: N dimensional vector of binary predictions: {0, 1}\n",
    "    \"\"\"\n",
    "    N, D = X.shape\n",
    "    preds = np.zeros(N) \n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    TODO: add your code here\n",
    "    \"\"\"      \n",
    "    assert preds.shape == (N,) \n",
    "    return preds\n",
    "\n",
    "\n",
    "def multinomial_train(X, y, C, \n",
    "                     w0=None, \n",
    "                     b0=None, \n",
    "                     step_size=0.5, \n",
    "                     max_iterations=1000):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    - X: training features, a N-by-D numpy array, where N is the \n",
    "    number of training points and D is the dimensionality of features\n",
    "    - y: multiclass training labels, a N dimensional numpy array where\n",
    "    N is the number of training points, indicating the labels of \n",
    "    training data\n",
    "    - C: number of classes in the data\n",
    "    - step_size: step size (learning rate)\n",
    "    - max_iterations: number of iterations to perform gradient descent\n",
    "\n",
    "    Returns:\n",
    "    - w: C-by-D weight matrix of multinomial logistic regression, where \n",
    "    C is the number of classes and D is the dimensionality of features.\n",
    "    - b: bias vector of length C, where C is the number of classes\n",
    "\n",
    "    Implement multinomial logistic regression for multiclass \n",
    "    classification. Again use the *average* of the gradients for all training \n",
    "    examples multiplied by the step_size to update parameters.\n",
    "    \n",
    "    You may find it useful to use a special (one-hot) representation of the labels, \n",
    "    where each label y_i is represented as a row of zeros with a single 1 in\n",
    "    the column, that corresponds to the class y_i.\n",
    "    \"\"\"\n",
    "\n",
    "    N, D = X.shape\n",
    "\n",
    "    w = np.zeros((C, D))\n",
    "    if w0 is not None:\n",
    "        w = w0\n",
    "    \n",
    "    b = np.zeros(C)\n",
    "    if b0 is not None:\n",
    "        b = b0\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    TODO: add your code here\n",
    "    \"\"\"\n",
    "\n",
    "    assert w.shape == (C, D)\n",
    "    assert b.shape == (C,)\n",
    "    return w, b\n",
    "\n",
    "\n",
    "def multinomial_predict(X, w, b):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    - X: testing features, a N-by-D numpy array, where N is the \n",
    "    number of training points and D is the dimensionality of features\n",
    "    - w: weights of the trained multinomial classifier\n",
    "    - b: bias terms of the trained multinomial classifier\n",
    "    \n",
    "    Returns:\n",
    "    - preds: N dimensional vector of multiclass predictions.\n",
    "    Outputted predictions should be from {0, C - 1}, where\n",
    "    C is the number of classes\n",
    "\n",
    "    Make predictions for multinomial classifier.\n",
    "    \"\"\"\n",
    "    N, D = X.shape\n",
    "    C = w.shape[0]\n",
    "    preds = np.zeros(N) \n",
    "\n",
    "    \"\"\"\n",
    "    TODO: add your code here\n",
    "    \"\"\"   \n",
    "\n",
    "    assert preds.shape == (N,)\n",
    "    return preds\n",
    "\n",
    "\n",
    "def OVR_train(X, y, C, w0=None, b0=None, step_size=0.5, max_iterations=1000):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    - X: training features, a N-by-D numpy array, where N is the \n",
    "    number of training points and D is the dimensionality of features\n",
    "    - y: multiclass training labels, a N dimensional numpy array, \n",
    "    indicating the labels of each training point\n",
    "    - C: number of classes in the data\n",
    "    - w0: initial value of weight matrix\n",
    "    - b0: initial value of bias term\n",
    "    - step_size: step size (learning rate)\n",
    "    - max_iterations: number of iterations to perform gradient descent\n",
    "\n",
    "    Returns:\n",
    "    - w: a C-by-D weight matrix of OVR logistic regression\n",
    "    - b: bias vector of length C\n",
    "\n",
    "    Implement multiclass classification using one-versus-rest with binary logistic \n",
    "    regression as the black-box. Recall that the one-versus-rest classifier is \n",
    "    trained by training C different classifiers. \n",
    "    \"\"\"\n",
    "    N, D = X.shape\n",
    "    \n",
    "    w = np.zeros((C, D))\n",
    "    if w0 is not None:\n",
    "        w = w0\n",
    "    \n",
    "    b = np.zeros(C)\n",
    "    if b0 is not None:\n",
    "        b = b0\n",
    "\n",
    "    \"\"\"\n",
    "    TODO: add your code here\n",
    "    \"\"\"\n",
    "    assert w.shape == (C, D), 'wrong shape of weights matrix'\n",
    "    assert b.shape == (C,), 'wrong shape of bias terms vector'\n",
    "    return w, b\n",
    "\n",
    "\n",
    "def OVR_predict(X, w, b):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    - X: testing features, a N-by-D numpy array, where N is the \n",
    "    number of training points and D is the dimensionality of features\n",
    "    - w: weights of the trained OVR model\n",
    "    - b: bias terms of the trained OVR model\n",
    "    \n",
    "    Returns:\n",
    "    - preds: vector of class label predictions.\n",
    "    Outputted predictions should be from {0, C - 1}, where\n",
    "    C is the number of classes.\n",
    "\n",
    "    Make predictions using OVR strategy and probability predictions from binary\n",
    "    classifiers. \n",
    "    \"\"\"\n",
    "    N, D = X.shape\n",
    "    C = w.shape[0]\n",
    "    preds = np.zeros(N) \n",
    "    \n",
    "    \"\"\"\n",
    "    TODO: add your code here\n",
    "    \"\"\"\n",
    "\n",
    "    assert preds.shape == (N,)\n",
    "    return preds\n",
    "\n",
    "\n",
    "#######################################################################\n",
    "# DO NOT MODIFY THE CODE BELOW \n",
    "#######################################################################\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def accuracy_score(true, preds):\n",
    "    return np.sum(true == preds).astype(float) / len(true)\n",
    "\n",
    "def run_binary():\n",
    "    from data_loader import toy_data_binary, \\\n",
    "                            data_loader_mnist \n",
    "\n",
    "    print('Performing binary classification on synthetic data')\n",
    "    X_train, X_test, y_train, y_test = toy_data_binary()\n",
    "        \n",
    "    w, b = binary_train(X_train, y_train)\n",
    "    \n",
    "    train_preds = binary_predict(X_train, w, b)\n",
    "    preds = binary_predict(X_test, w, b)\n",
    "    print('train acc: %f, test acc: %f' % \n",
    "            (accuracy_score(y_train, train_preds),\n",
    "             accuracy_score(y_test, preds)))\n",
    "    \n",
    "    print('Performing binary classification on binarized MNIST')\n",
    "    X_train, X_test, y_train, y_test = data_loader_mnist()\n",
    "\n",
    "    binarized_y_train = [0 if yi < 5 else 1 for yi in y_train] \n",
    "    binarized_y_test = [0 if yi < 5 else 1 for yi in y_test] \n",
    "    \n",
    "    w, b = binary_train(X_train, binarized_y_train)\n",
    "    \n",
    "    train_preds = binary_predict(X_train, w, b)\n",
    "    preds = binary_predict(X_test, w, b)\n",
    "    print('train acc: %f, test acc: %f' % \n",
    "            (accuracy_score(binarized_y_train, train_preds),\n",
    "             accuracy_score(binarized_y_test, preds)))\n",
    "\n",
    "def run_multiclass():\n",
    "    from data_loader import toy_data_multiclass_3_classes_non_separable, \\\n",
    "                            toy_data_multiclass_5_classes, \\\n",
    "                            data_loader_mnist \n",
    "    \n",
    "    datasets = [(toy_data_multiclass_3_classes_non_separable(), \n",
    "                        'Synthetic data', 3), \n",
    "                (toy_data_multiclass_5_classes(), 'Synthetic data', 5), \n",
    "                (data_loader_mnist(), 'MNIST', 10)]\n",
    "\n",
    "    for data, name, num_classes in datasets:\n",
    "        print('%s: %d class classification' % (name, num_classes))\n",
    "        X_train, X_test, y_train, y_test = data\n",
    "        \n",
    "        print('One-versus-rest:')\n",
    "        w, b = OVR_train(X_train, y_train, C=num_classes)\n",
    "        train_preds = OVR_predict(X_train, w=w, b=b)\n",
    "        preds = OVR_predict(X_test, w=w, b=b)\n",
    "        print('train acc: %f, test acc: %f' % \n",
    "            (accuracy_score(y_train, train_preds),\n",
    "             accuracy_score(y_test, preds)))\n",
    "    \n",
    "        print('Multinomial:')\n",
    "        w, b = multinomial_train(X_train, y_train, C=num_classes)\n",
    "        train_preds = multinomial_predict(X_train, w=w, b=b)\n",
    "        preds = multinomial_predict(X_test, w=w, b=b)\n",
    "        print('train acc: %f, test acc: %f' % \n",
    "            (accuracy_score(y_train, train_preds),\n",
    "             accuracy_score(y_test, preds)))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    import argparse\n",
    "    import sys\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--type\", )\n",
    "    parser.add_argument(\"--output\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if args.output:\n",
    "            sys.stdout = open(args.output, 'w')\n",
    "\n",
    "    if not args.type or args.type == 'binary':\n",
    "        run_binary()\n",
    "\n",
    "    if not args.type or args.type == 'multiclass':\n",
    "        run_multiclass()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
