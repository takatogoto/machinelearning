{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist test acc \n",
      "\n",
      "k=100_lambda=0.01: test acc = 0.7980 \n",
      "\n",
      "k=100_lambda=0.1: test acc = 0.8140 \n",
      "\n",
      "k=100_lambda=1: test acc = 0.7880 \n",
      "\n",
      "k=1_lambda=0.1: test acc = 0.7790 \n",
      "\n",
      "k=10_lambda=0.1: test acc = 0.7980 \n",
      "\n",
      "k=1000_lambda=0.1: test acc = 0.8200 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "###### Q1.1 ######\n",
    "def objective_function(X, y, w, lamb):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    - Xtrain: A 2 dimensional numpy array of data (number of samples x number of features)\n",
    "    - ytrain: A 1 dimensional numpy array of labels (length = number of samples )\n",
    "    - w: a numpy array of D elements as a D-dimension weight vector\n",
    "    - lamb: lambda used in pegasos algorithm\n",
    "\n",
    "    Return:\n",
    "    - obj_value: the value of objective function in SVM primal formulation\n",
    "    \"\"\"\n",
    "    # you need to fill in your solution here\n",
    "    \n",
    "    # 0.5 * lamb * ||w||^2 + 1/N sum(max(0,1-ywx))  \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    N = X.shape[0]\n",
    "    z = 1- np.multiply(y, np.transpose(np.dot(X,w)))\n",
    "    zmax = z[z>0]\n",
    "    obj_value = 0.5 * lamb * (np.linalg.norm(w) **2) + np.sum(zmax) / N\n",
    "    #print(obj_value)\n",
    "\n",
    "    return obj_value\n",
    "\n",
    "\n",
    "###### Q1.2 ######\n",
    "def pegasos_train(Xtrain, ytrain, w, lamb, k, max_iterations):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    - Xtrain: A list of num_train elements, where each element is a list of D-dimensional features.\n",
    "    - ytrain: A list of num_train labels\n",
    "    - w: a numpy array of D elements as a D-dimension vector, which is the weight vector and initialized to be all 0s\n",
    "    - lamb: lambda used in pegasos algorithm\n",
    "    - k: mini-batch size\n",
    "    - max_iterations: the total number of iterations to update parameters\n",
    "\n",
    "    Returns:\n",
    "    - learnt w\n",
    "    - train_obj: a list of the objective function value at each iteration during the training process, length of 500.\n",
    "    \"\"\"\n",
    "    np.random.seed(0)\n",
    "    Xtrain = np.array(Xtrain)\n",
    "    ytrain = np.array(ytrain)\n",
    "    N = Xtrain.shape[0]\n",
    "    D = Xtrain.shape[1]\n",
    "\n",
    "    train_obj = []\n",
    "\n",
    "    for iter in range(1, max_iterations + 1):\n",
    "        A_t = np.floor(np.random.rand(k) * N).astype(int)  # index of the current mini-batch\n",
    "\n",
    "        # you need to fill in your solution here\n",
    "        X_t = Xtrain[A_t, :]\n",
    "        y_t = ytrain[A_t]\n",
    "        \n",
    "        # 4\n",
    "        #A_tpls = A_t[np.multiply(y_t, np.dot(X_t,w)) < 1]\n",
    "        A_tpls = A_t[(np.multiply(y_t, np.transpose(np.dot(X_t,w)) )<1).ravel()]\n",
    "        X_tpls = Xtrain[A_tpls, :]\n",
    "        y_tpls = ytrain[A_tpls]\n",
    "        \n",
    "        # 5\n",
    "        ita_t = 1/(lamb * iter)\n",
    "        \n",
    "        \n",
    "        # 6\n",
    "        w_thalf = (1 - (ita_t * lamb)) * w + ita_t * np.sum(\n",
    "            np.multiply(y_tpls.reshape(y_tpls.shape[0],1),X_tpls),\n",
    "            axis=0).reshape(D,1)/ k\n",
    "        \n",
    "        # 7\n",
    "        #w = w_thalf * min(1,1/(np.sqrt(lamb) * np.linalg.norm(np.array(w_thalf))))\n",
    "        if not np.linalg.norm(w_thalf) ==0:\n",
    "            w = w_thalf * min(1, 1 / np.sqrt(lamb) / np.linalg.norm(w_thalf))\n",
    "        else:\n",
    "            w = w_thal\n",
    "        \n",
    "        train_obj.append(objective_function(Xtrain, ytrain, w, lamb))\n",
    "        # print(train_obj[iter-1])\n",
    "        # print(w[0])\n",
    "    \n",
    "\n",
    "    return w, train_obj\n",
    "\n",
    "\n",
    "###### Q1.3 ######\n",
    "def pegasos_test(Xtest, ytest, w_l):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    - Xtest: A list of num_test elements, where each element is a list of D-dimensional features.\n",
    "    - ytest: A list of num_test labels\n",
    "    - w_l: a numpy array of D elements as a D-dimension vector, which is the weight vector of SVM classifier and learned by pegasos_train()\n",
    " \n",
    "    Returns:\n",
    "    - test_acc: testing accuracy.\n",
    "    \"\"\"\n",
    "    # you need to fill in your solution here\n",
    "    Xtest = np.array(Xtest)\n",
    "    ytest = np.array(ytest)\n",
    "    N = Xtest.shape[0]\n",
    "    wx = np.sign(np.dot(Xtest, w_l).ravel())\n",
    "    test_acc = np.sum(ytest.ravel() == wx)/N\n",
    "\n",
    "\n",
    "    return test_acc\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "NO MODIFICATIONS below this line.\n",
    "You should only write your code in the above functions.\n",
    "\"\"\"\n",
    "\n",
    "def data_loader_mnist(dataset):\n",
    "\n",
    "    with open(dataset, 'r') as f:\n",
    "            data_set = json.load(f)\n",
    "    train_set, valid_set, test_set = data_set['train'], data_set['valid'], data_set['test']\n",
    "\n",
    "    Xtrain = train_set[0]\n",
    "    ytrain = train_set[1]\n",
    "    Xvalid = valid_set[0]\n",
    "    yvalid = valid_set[1]\n",
    "    Xtest = test_set[0]\n",
    "    ytest = test_set[1]\n",
    "\n",
    "    ## below we add 'one' to the feature of each sample, such that we include the bias term into parameter w\n",
    "    Xtrain = np.hstack((np.ones((len(Xtrain), 1)), np.array(Xtrain))).tolist()\n",
    "    Xvalid = np.hstack((np.ones((len(Xvalid), 1)), np.array(Xvalid))).tolist()\n",
    "    Xtest = np.hstack((np.ones((len(Xtest), 1)), np.array(Xtest))).tolist()\n",
    "\n",
    "    for i, v in enumerate(ytrain):\n",
    "        if v < 5:\n",
    "            ytrain[i] = -1.\n",
    "        else:\n",
    "            ytrain[i] = 1.\n",
    "    for i, v in enumerate(ytest):\n",
    "        if v < 5:\n",
    "            ytest[i] = -1.\n",
    "        else:\n",
    "            ytest[i] = 1.\n",
    "\n",
    "    return Xtrain, ytrain, Xvalid, yvalid, Xtest, ytest\n",
    "\n",
    "\n",
    "def pegasos_mnist():\n",
    "\n",
    "    test_acc = {}\n",
    "    train_obj = {}\n",
    "\n",
    "    Xtrain, ytrain, Xvalid, yvalid, Xtest, ytest = data_loader_mnist(dataset = 'mnist_subset.json')\n",
    "\n",
    "    max_iterations = 500\n",
    "    k = 100\n",
    "    for lamb in (0.01, 0.1, 1):\n",
    "        w = np.zeros((len(Xtrain[0]), 1))\n",
    "        w_l, train_obj['k=' + str(k) + '_lambda=' + str(lamb)] = pegasos_train(Xtrain, ytrain, w, lamb, k, max_iterations)\n",
    "        test_acc['k=' + str(k) + '_lambda=' + str(lamb)] = pegasos_test(Xtest, ytest, w_l)\n",
    "\n",
    "    lamb = 0.1\n",
    "    for k in (1, 10, 1000):\n",
    "        w = np.zeros((len(Xtrain[0]), 1))\n",
    "        w_l, train_obj['k=' + str(k) + '_lambda=' + str(lamb)] = pegasos_train(Xtrain, ytrain, w, lamb, k, max_iterations)\n",
    "        test_acc['k=' + str(k) + '_lambda=' + str(lamb)] = pegasos_test(Xtest, ytest, w_l)\n",
    "\n",
    "    return test_acc, train_obj\n",
    "\n",
    "\n",
    "def main():\n",
    "    test_acc, train_obj = pegasos_mnist() # results on mnist\n",
    "    print('mnist test acc \\n')\n",
    "    for key, value in test_acc.items():\n",
    "        print('%s: test acc = %.4f \\n' % (key, value))\n",
    "\n",
    "    with open('pegasos.json', 'w') as f_json:\n",
    "        json.dump([test_acc, train_obj], f_json)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, ytrain, Xvalid, yvalid, Xtest, ytest = data_loader_mnist(dataset = 'mnist_subset.json')\n",
    "X = np.array(Xtrain)\n",
    "y = np.array(ytrain)\n",
    "N = X.shape[0]\n",
    "D = X.shape[1]\n",
    "w = np.ones((D,1))\n",
    "lamb = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # 0.5 * lamb * ||w||^2 + 1/N sum(max(0,1-ywx)) \n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    D = X.shape[1]\n",
    "    z = 1- np.multiply(y, np.transpose(np.dot(X,w)))\n",
    "    zmax = z[z>0]\n",
    "    obj_value = 0.5 * lamb * (np.linalg.norm(w) **2 ) + np.sum(zmax) / N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1000\n",
    "max_iterations = 500\n",
    "w = np.zeros((D,1))\n",
    "lamb = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92710240317173\n",
      "2.799573665940772\n",
      "1.1711735104241636\n",
      "0.9889135417648544\n",
      "0.9507995012292567\n",
      "0.8135716991462694\n",
      "0.806213791613021\n",
      "0.7972111617010312\n",
      "0.777981848338262\n",
      "0.7784166338498772\n",
      "0.7660148351239452\n",
      "0.7599369389699608\n",
      "0.7423080670210762\n",
      "0.722839954521328\n",
      "0.7053444499392916\n",
      "0.683891753595169\n",
      "0.6746281030101371\n",
      "0.6597227635703051\n",
      "0.6587316366586422\n",
      "0.6514266087965418\n",
      "0.6499520610937997\n",
      "0.6437100845025393\n",
      "0.6384841266150869\n",
      "0.6387445229591764\n",
      "0.6353801553762549\n",
      "0.6345829322932705\n",
      "0.6360677096197667\n",
      "0.6357822021946509\n",
      "0.6346700106076135\n",
      "0.6358877974737873\n",
      "0.6370034297516821\n",
      "0.6377325956981745\n",
      "0.6393059567515549\n",
      "0.6413408164709637\n",
      "0.6416703450346182\n",
      "0.6431953134069864\n",
      "0.6426174109006499\n",
      "0.6436415562621193\n",
      "0.6446427383826484\n",
      "0.6441188046849974\n",
      "0.646722226391053\n",
      "0.6474462356627982\n",
      "0.6478054836228516\n",
      "0.6492287742852973\n",
      "0.6487519910274467\n",
      "0.6493102121167028\n",
      "0.6497024909245699\n",
      "0.6501100148282885\n",
      "0.6483127910063562\n",
      "0.6478933977899984\n",
      "0.6491467282660388\n",
      "0.6491302939483538\n",
      "0.6495006637416867\n",
      "0.6504708142130751\n",
      "0.6510152472831916\n",
      "0.649589652460997\n",
      "0.6505815705254828\n",
      "0.6493554723858775\n",
      "0.6494102281486295\n",
      "0.6495563093799133\n",
      "0.6495005188154803\n",
      "0.6507697806150861\n",
      "0.6532660457047944\n",
      "0.6526967370903144\n",
      "0.6527140967204207\n",
      "0.6526689086350392\n",
      "0.6532556506128206\n",
      "0.6530308921002305\n",
      "0.6543800623474485\n",
      "0.6548172415900626\n",
      "0.6554093353149831\n",
      "0.6554708836642631\n",
      "0.6554564513917405\n",
      "0.6559709975417773\n",
      "0.6570858721223557\n",
      "0.6561784110713239\n",
      "0.6572289720297984\n",
      "0.6557741551632358\n",
      "0.6555653432149992\n",
      "0.6557094916570013\n",
      "0.6572190286115198\n",
      "0.6561805690324363\n",
      "0.6565312205049654\n",
      "0.6561507594145375\n",
      "0.657414218335903\n",
      "0.6586689690440786\n",
      "0.6581098253168844\n",
      "0.6589664669200423\n",
      "0.6585894972165132\n",
      "0.6593346859225887\n",
      "0.6589495808418817\n",
      "0.6586134086694864\n",
      "0.6583975194322712\n",
      "0.6585160937040592\n",
      "0.6583944790137042\n",
      "0.6589479688395337\n",
      "0.6580858079336964\n",
      "0.6574467343573889\n",
      "0.6577796600956503\n",
      "0.6573235289585423\n",
      "0.6565541425006095\n",
      "0.6566763705013863\n",
      "0.6572060231626199\n",
      "0.6571948483396214\n",
      "0.6578321903553956\n",
      "0.6580277368652703\n",
      "0.6587438004919761\n",
      "0.6592037384683437\n",
      "0.6599803903318512\n",
      "0.6596118446199148\n",
      "0.6594641748137394\n",
      "0.660063374114062\n",
      "0.6597495624840303\n",
      "0.6598925956885529\n",
      "0.6595254718926359\n",
      "0.6595240628950838\n",
      "0.6594266119436529\n",
      "0.6589855455957496\n",
      "0.6589547017068395\n",
      "0.6590026701126552\n",
      "0.6591185154824144\n",
      "0.6584516213315098\n",
      "0.6582968892111892\n",
      "0.6577473759173205\n",
      "0.657269051540348\n",
      "0.6581425482823797\n",
      "0.6576199879968588\n",
      "0.6575045174443527\n",
      "0.6576855611419922\n",
      "0.6573985711326462\n",
      "0.6574127944237534\n",
      "0.6578211415053027\n",
      "0.6580859573577267\n",
      "0.6585109859240892\n",
      "0.6584029914047975\n",
      "0.6587647026948474\n",
      "0.6582955705099172\n",
      "0.658691414232594\n",
      "0.6588874373836767\n",
      "0.6592249183608446\n",
      "0.6593632759263912\n",
      "0.659484216590506\n",
      "0.6598909213480313\n",
      "0.6596815924152319\n",
      "0.6596256354113554\n",
      "0.6597947253628496\n",
      "0.6596148711556065\n",
      "0.6596567314983315\n",
      "0.6598193776109403\n",
      "0.6594859066068828\n",
      "0.658589409036096\n",
      "0.6586923164166059\n",
      "0.6586473429448906\n",
      "0.6584144012992357\n",
      "0.6587265043389917\n",
      "0.6587450041792119\n",
      "0.6583203280885079\n",
      "0.6588061455936448\n",
      "0.6586433627891088\n",
      "0.6586949065593606\n",
      "0.6585964091002041\n",
      "0.658190953896696\n",
      "0.658563503439795\n",
      "0.6586805966727669\n",
      "0.6586174239479755\n",
      "0.6584175576466285\n",
      "0.6579104649532382\n",
      "0.657750896007799\n",
      "0.6578376619492405\n",
      "0.6575972328135968\n",
      "0.6574758621517106\n",
      "0.6574885407985779\n",
      "0.6573895594545519\n",
      "0.6573975278584167\n",
      "0.6574081675050827\n",
      "0.6573922046784287\n",
      "0.6573172110514292\n",
      "0.6573840189980296\n",
      "0.6573918956799032\n",
      "0.6577173497752918\n",
      "0.658006334528044\n",
      "0.6582106960310362\n",
      "0.6581160370777122\n",
      "0.6578894513129461\n",
      "0.6585313719195467\n",
      "0.6579252881478003\n",
      "0.6579112619147613\n",
      "0.6578305268971553\n",
      "0.6577297407551072\n",
      "0.6579299482860745\n",
      "0.6578238824830736\n",
      "0.6580659601852258\n",
      "0.6579102583890035\n",
      "0.6582996916547973\n",
      "0.6579905453302294\n",
      "0.6583144756418577\n",
      "0.6586807241719064\n",
      "0.658804881051591\n",
      "0.6589608457415491\n",
      "0.6592346865053325\n",
      "0.6594452343728294\n",
      "0.6593868354189221\n",
      "0.6590216556457742\n",
      "0.6593587400923426\n",
      "0.659061392193687\n",
      "0.6586936665407899\n",
      "0.6582430857579467\n",
      "0.6580966139404746\n",
      "0.6585371586586081\n",
      "0.6585700600043487\n",
      "0.6588801472428579\n",
      "0.6587582377733235\n",
      "0.6588502031614426\n",
      "0.6590602092134776\n",
      "0.6591533888067237\n",
      "0.6592962097170726\n",
      "0.6592362753638582\n",
      "0.659676399740911\n",
      "0.6591022957094783\n",
      "0.6587140168497859\n",
      "0.6586313897697568\n",
      "0.6588695186859743\n",
      "0.6586256437439247\n",
      "0.65857173207492\n",
      "0.6589246065029802\n",
      "0.6588150044325563\n",
      "0.6587706496813267\n",
      "0.6584198468030332\n",
      "0.6584689519752653\n",
      "0.6585414854773949\n",
      "0.6588724021918175\n",
      "0.658882807254176\n",
      "0.6590809299835083\n",
      "0.6591177974194805\n",
      "0.6593141050581159\n",
      "0.659652414202752\n",
      "0.6596661679500512\n",
      "0.6599733475039464\n",
      "0.6595044062278176\n",
      "0.6592989130260118\n",
      "0.6593681220808346\n",
      "0.6594262725285844\n",
      "0.659641305625416\n",
      "0.65963831720806\n",
      "0.6594800959496785\n",
      "0.6591146659444412\n",
      "0.6592422734598229\n",
      "0.6590797239401905\n",
      "0.6591157505208879\n",
      "0.6591813830539894\n",
      "0.6593572739751357\n",
      "0.6589624557662118\n",
      "0.6591063999862353\n",
      "0.6590730934268395\n",
      "0.658933196976109\n",
      "0.6588846794157532\n",
      "0.6591399813913629\n",
      "0.6593619323203697\n",
      "0.6593693553071407\n",
      "0.6592103059807742\n",
      "0.6590858398577237\n",
      "0.6590148925885473\n",
      "0.658841710045502\n",
      "0.658965655125839\n",
      "0.659118112644086\n",
      "0.6593083563468416\n",
      "0.6590110012287158\n",
      "0.658853213778897\n",
      "0.658950200565096\n",
      "0.6589450129895763\n",
      "0.6588866884233828\n",
      "0.6590117300538894\n",
      "0.6590459249141645\n",
      "0.6587589510038943\n",
      "0.6588601945382374\n",
      "0.6589799510833683\n",
      "0.6590169807976116\n",
      "0.6590318557213887\n",
      "0.6588096187172475\n",
      "0.6587321753757327\n",
      "0.6586483286639775\n",
      "0.6586328513004219\n",
      "0.6587515644015207\n",
      "0.6587725569343512\n",
      "0.6589484806051689\n",
      "0.65893960047484\n",
      "0.659051093829102\n",
      "0.6591704805063033\n",
      "0.6593539674721097\n",
      "0.6593775457071193\n",
      "0.6595453765538721\n",
      "0.6597916285633175\n",
      "0.6601819530269568\n",
      "0.6599832424211303\n",
      "0.6597552641562019\n",
      "0.659684439177369\n",
      "0.6597007222075367\n",
      "0.6598638357641846\n",
      "0.6597259517067888\n",
      "0.6595019210136509\n",
      "0.6595395052202987\n",
      "0.6600382921284991\n",
      "0.6601156212190781\n",
      "0.65996523957379\n",
      "0.6598758257101639\n",
      "0.6599206767333703\n",
      "0.6599405666884293\n",
      "0.6597884844405775\n",
      "0.6596690930802721\n",
      "0.6596637269737284\n",
      "0.6596193977540926\n",
      "0.6597054776654083\n",
      "0.6597815503042043\n",
      "0.6596873168832031\n",
      "0.6598355483877506\n",
      "0.6598876102903358\n",
      "0.6598960463518652\n",
      "0.6599596276604984\n",
      "0.6599907902018861\n",
      "0.66011866840293\n",
      "0.6603734395299685\n",
      "0.6604314952064665\n",
      "0.6603805971300875\n",
      "0.6604895766653027\n",
      "0.6603942835192581\n",
      "0.6603273010787959\n",
      "0.6601592291804294\n",
      "0.6599987578642957\n",
      "0.6601375472262644\n",
      "0.6602626189293738\n",
      "0.660060116738255\n",
      "0.6599187316945441\n",
      "0.6601376010682309\n",
      "0.6600978547652804\n",
      "0.6602482169125764\n",
      "0.6602044655299322\n",
      "0.6602542826204866\n",
      "0.6601410251558281\n",
      "0.6601066153864128\n",
      "0.6600631601060892\n",
      "0.6596898180131721\n",
      "0.659576019762427\n",
      "0.6594122667302307\n",
      "0.6593987980386602\n",
      "0.6596630564589555\n",
      "0.6598611829647183\n",
      "0.659763780595012\n",
      "0.6598021340345881\n",
      "0.6597332276694956\n",
      "0.6598641291558769\n",
      "0.6598900913332452\n",
      "0.6600333460050111\n",
      "0.6601995716221772\n",
      "0.6602904588822731\n",
      "0.6605017323912763\n",
      "0.6605361264897049\n",
      "0.6605374891897856\n",
      "0.6606181872912762\n",
      "0.6604773335645853\n",
      "0.6599540857615986\n",
      "0.6600380306254806\n",
      "0.6601980734233923\n",
      "0.6602375870643927\n",
      "0.6600618075016874\n",
      "0.6601257788755422\n",
      "0.6600040605807093\n",
      "0.6600688973042536\n",
      "0.6600518665186182\n",
      "0.6599314103267464\n",
      "0.6597241898398615\n",
      "0.6596368598613341\n",
      "0.6598228254003944\n",
      "0.6599076320288182\n",
      "0.6601102147617074\n",
      "0.6599033728748298\n",
      "0.6598257264722335\n",
      "0.659764699446544\n",
      "0.6596896600333059\n",
      "0.6594674945905808\n",
      "0.6594251193893147\n",
      "0.659375496895376\n",
      "0.6594945997716003\n",
      "0.6594853333264031\n",
      "0.6595053026448668\n",
      "0.6595528853940238\n",
      "0.6593813980461052\n",
      "0.6594609633115328\n",
      "0.6596397530022142\n",
      "0.6595294373796278\n",
      "0.6594211587967514\n",
      "0.6594691340943768\n",
      "0.6595197715204159\n",
      "0.6597161519384295\n",
      "0.65978009795981\n",
      "0.6599511955864851\n",
      "0.6599579686469499\n",
      "0.6600238324926527\n",
      "0.6597742750865976\n",
      "0.6598143126373964\n",
      "0.6599423248308449\n",
      "0.6601891108823588\n",
      "0.660004736506927\n",
      "0.659831796641405\n",
      "0.659780658368622\n",
      "0.6599947568733164\n",
      "0.6600233889737581\n",
      "0.6600446440216146\n",
      "0.6601406027133057\n",
      "0.660214415794356\n",
      "0.6603268104057627\n",
      "0.6602650076577757\n",
      "0.6601435903502878\n",
      "0.6601253132073415\n",
      "0.660310944607467\n",
      "0.6604638002704413\n",
      "0.6604605503452309\n",
      "0.6604859109734381\n",
      "0.6602912263393494\n",
      "0.6602321752211731\n",
      "0.6602724377088908\n",
      "0.6603815735634562\n",
      "0.660359589703314\n",
      "0.6603322564077021\n",
      "0.6603275915159896\n",
      "0.6602452419032864\n",
      "0.6601849807299851\n",
      "0.6602695957021352\n",
      "0.6602684884155033\n",
      "0.6603228150756587\n",
      "0.6604459270915157\n",
      "0.6602683656895172\n",
      "0.6603206233710914\n",
      "0.6604060093239068\n",
      "0.6605947070325868\n",
      "0.660622297976968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6605793023934641\n",
      "0.6606120419465682\n",
      "0.6606437446820828\n",
      "0.6604954081444636\n",
      "0.6605713358359695\n",
      "0.6607344139339268\n",
      "0.660660102156858\n",
      "0.6608213879102097\n",
      "0.6609459319219592\n",
      "0.6610891096477404\n",
      "0.6610447450375068\n",
      "0.6610806377160064\n",
      "0.6611882072494224\n",
      "0.6611009097744428\n",
      "0.6610873917302088\n",
      "0.6609851025749343\n",
      "0.6610787197464252\n",
      "0.661079010289029\n",
      "0.6611261771464209\n",
      "0.6611069042275738\n",
      "0.6611047878247794\n",
      "0.6613063097487396\n",
      "0.6614783844361928\n",
      "0.6615902075688275\n",
      "0.6615965596020259\n",
      "0.6615172379255501\n",
      "0.661632753702657\n",
      "0.6616415918650884\n",
      "0.6616199588518415\n",
      "0.6616331088620907\n",
      "0.6616399329509869\n",
      "0.6615504795435987\n",
      "0.6617186127102825\n",
      "0.6615503630516615\n",
      "0.6613830970316122\n",
      "0.6614454740116438\n",
      "0.6613945668865788\n",
      "0.6614979494003004\n",
      "0.6614697492716395\n",
      "0.6616462414698259\n",
      "0.6616167141128829\n",
      "0.6615479677567739\n",
      "0.6616369136237218\n",
      "0.6614480983526081\n",
      "0.6615662691869798\n",
      "0.6615812040538062\n",
      "0.661528348958158\n",
      "0.6616196085992502\n",
      "0.6615584205997087\n",
      "0.6617011905660377\n",
      "0.6617179432289645\n",
      "0.6616093963972549\n",
      "0.6615111178052799\n",
      "0.6613977964625748\n",
      "0.661401874503815\n",
      "0.6614425226467299\n",
      "0.6613167504382758\n",
      "0.6612067832154638\n",
      "0.6611548849444028\n",
      "0.6610995885729892\n",
      "0.6610699000103644\n",
      "0.660964589086499\n",
      "0.6609858230189816\n",
      "0.6610219081041049\n",
      "0.6610206108376625\n"
     ]
    }
   ],
   "source": [
    "    \"\"\"\n",
    "    Inputs:\n",
    "    - Xtrain: A list of num_train elements, where each element is a list of D-dimensional features.\n",
    "    - ytrain: A list of num_train labels\n",
    "    - w: a numpy array of D elements as a D-dimension vector, which is the weight vector and initialized to be all 0s\n",
    "    - lamb: lambda used in pegasos algorithm\n",
    "    - k: mini-batch size\n",
    "    - max_iterations: the total number of iterations to update parameters\n",
    "\n",
    "    Returns:\n",
    "    - learnt w\n",
    "    - train_obj: a list of the objective function value at each iteration during the training process, length of 500.\n",
    "    \"\"\"\n",
    "    np.random.seed(0)\n",
    "    Xtrain = np.array(Xtrain)\n",
    "    ytrain = np.array(ytrain)\n",
    "    N = Xtrain.shape[0]\n",
    "    D = Xtrain.shape[1]\n",
    "\n",
    "    train_obj = []\n",
    "\n",
    "    for iter in range(1, max_iterations + 1):\n",
    "#    for iter in range(1,30):\n",
    "        A_t = np.floor(np.random.rand(k) * N).astype(int)  # index of the current mini-batch\n",
    "\n",
    "        # you need to fill in your solution here\n",
    "        X_t = Xtrain[A_t, :]\n",
    "        y_t = ytrain[A_t].astype(int)\n",
    "        \n",
    "        # 4\n",
    "        A_tpls = A_t[(np.multiply(y_t, np.transpose(np.dot(X_t, w)))<1).ravel()]\n",
    "        X_tpls = Xtrain[A_tpls, :]\n",
    "        y_tpls = ytrain[A_tpls].astype(int)\n",
    "        #print('min', min(y_tpls))\n",
    "        #print('max', max(y_tpls))\n",
    "        \n",
    "        # 5\n",
    "        ita_t = 1/(lamb * iter)\n",
    "        #print(ita_t)\n",
    "        \n",
    "        # 6\n",
    "        w_thalf = (1-ita_t * lamb) * w + (ita_t / k) * np.sum(\n",
    "            np.multiply(y_tpls.reshape(y_tpls.shape[0], 1), X_tpls),\n",
    "            axis=0).reshape(D,1)\n",
    "        \n",
    "        # 7\n",
    "        #w = w_thalf * min(1,1/(np.sqrt(lamb) * np.linalg.norm(np.array(w_thalf))))\n",
    "        w_ = w\n",
    "        print(np.linalg.norm(w_thalf))\n",
    "        w = w_thalf * min(1, 1/(np.sqrt(lamb) * np.linalg.norm(w_thalf)))\n",
    "\n",
    "        train_obj.append(objective_function(X_t, y_t, w, lamb))\n",
    "        #print(train_obj[iter-1])\n",
    "        \n",
    "    #print(train_obj)\n",
    "\n",
    "\n",
    "    #return w, train_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### line 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2716, 1980,  929, 3041,  557, 4739, 2351, 4039,   99, 2166])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_t[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2716, 1980,  929,  557, 4739, 2351, 4039,   99, 2166, 4460])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_tpls[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.1171875  0.5625     0.8125     0.99609375\n",
      " 0.95703125 0.5703125  0.5703125  0.0859375  0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.265625\n",
      " 0.92578125 0.98828125 0.98828125 0.98828125 0.98828125 0.98828125\n",
      " 0.98828125 0.5859375  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.23828125 0.94140625 0.98828125 0.98828125\n",
      " 0.9765625  0.81640625 0.765625   0.98828125 0.98828125 0.8828125\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.0546875\n",
      " 0.90625    0.98828125 0.98828125 0.80859375 0.14453125 0.\n",
      " 0.0703125  0.93359375 0.98828125 0.8828125  0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.3203125  0.98828125 0.98828125\n",
      " 0.8828125  0.05859375 0.         0.         0.         0.65625\n",
      " 0.98828125 0.75       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.3203125  0.98828125 0.98828125 0.80859375 0.0390625\n",
      " 0.         0.         0.078125   0.95703125 0.98828125 0.46484375\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.3203125\n",
      " 0.98828125 0.98828125 0.98828125 0.08203125 0.         0.\n",
      " 0.4296875  0.98828125 0.98828125 0.203125   0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.07421875 0.765625   0.98828125\n",
      " 0.98828125 0.75390625 0.125      0.27734375 0.9765625  0.98828125\n",
      " 0.6953125  0.01171875 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.23828125 0.77734375 0.98828125 0.98828125\n",
      " 0.9375     0.9375     0.98828125 0.9765625  0.2109375  0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.0703125  0.75390625 0.98828125 0.98828125 0.98828125\n",
      " 0.98828125 0.66796875 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.07421875 0.7734375  0.98828125 0.98828125 0.98828125 0.3359375\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.5234375\n",
      " 0.98828125 0.98828125 0.98828125 0.8515625  0.09765625 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.91015625 0.98828125 0.98828125\n",
      " 0.98828125 0.98828125 0.1875     0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.27734375 0.9765625  0.98828125 0.828125   0.98828125 0.98828125\n",
      " 0.52734375 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.74609375 0.98828125\n",
      " 0.875      0.11328125 0.93359375 0.98828125 0.8125     0.0234375\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.76171875 0.98828125 0.4921875  0.\n",
      " 0.9296875  0.98828125 0.98828125 0.0390625  0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.76171875 0.98828125 0.79296875 0.38671875 0.98046875 0.98828125\n",
      " 0.98828125 0.0390625  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.3046875  0.98046875\n",
      " 0.98828125 0.984375   0.98828125 0.98828125 0.5625     0.00390625\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.49609375 0.98828125 0.98828125\n",
      " 0.98828125 0.98828125 0.1875     0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.01171875 0.41796875 0.74609375 0.56640625 0.46875\n",
      " 0.02734375 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.        ]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain[2176,:])\n",
    "print(ytrain[2176])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.63172475])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.multiply(ytrain[2176], np.transpose(np.dot(Xtrain[2176,:], w_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.3147609])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.multiply(ytrain[3041], np.transpose(np.dot(Xtrain[3041,:], w_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6611226985854638"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(w_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(735, 1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(X_tpls, w_).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(735, 1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tpls.reshape(y_tpls.shape[0], 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0    -1]\n",
      " [   -2    -3]\n",
      " [    4     5]\n",
      " ...\n",
      " [-1464 -1465]\n",
      " [-1466 -1467]\n",
      " [ 1468  1469]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array(range(X_tpls.shape[0]*2)).reshape((X_tpls.shape[0],2))\n",
    "print(np.multiply(y_tpls.reshape(y_tpls.shape[0], 1) ,a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22438, 22467])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum( np.multiply(y_tpls.reshape(y_tpls.shape[0], 1) ,a), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### line 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/lamb/iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/(lamb * iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### line 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.998"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-ita_t * lamb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.998"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - (ita_t * lamb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(785, 1)\n",
      "[[0.01638692]\n",
      " [0.02061471]\n",
      " [0.02567001]\n",
      " [0.0257776 ]\n",
      " [0.02368338]]\n"
     ]
    }
   ],
   "source": [
    "print(((1-ita_t * lamb) * w_).shape)\n",
    "print(((1-ita_t * lamb) * w_)[100:105])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4e-06"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ita_t / k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(785, 1)\n",
      "[[14.24609375]\n",
      " [16.66796875]\n",
      " [15.91796875]\n",
      " [15.1953125 ]\n",
      " [11.6875    ]]\n"
     ]
    }
   ],
   "source": [
    "print((np.sum(np.multiply(y_tpls.reshape(y_tpls.shape[0], 1), X_tpls),\n",
    "            axis=0).reshape(D,1)).shape)\n",
    "print((np.sum(np.multiply(y_tpls.reshape(y_tpls.shape[0], 1), X_tpls),\n",
    "            axis=0).reshape(D,1))[100:105])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00098249],\n",
       "       [0.00114952],\n",
       "       [0.00109779],\n",
       "       [0.00104795],\n",
       "       [0.00080603]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((ita_t / k) * np.sum(np.multiply(y_tpls.reshape(y_tpls.shape[0], 1), X_tpls),\n",
    "            axis=0).reshape(D,1))[100:105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(785, 1)\n",
      "[[ 8.90234375]\n",
      " [13.3671875 ]\n",
      " [12.6484375 ]\n",
      " [16.43359375]\n",
      " [12.70703125]]\n"
     ]
    }
   ],
   "source": [
    "print((np.sum(np.multiply(y_t.reshape(y_t.shape[0], 1), X_t),\n",
    "            axis=0).reshape(D,1)).shape)\n",
    "print((np.sum(np.multiply(y_t.reshape(y_t.shape[0], 1), X_t),\n",
    "            axis=0).reshape(D,1))[100:105])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### line 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.414213562373095"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/np.sqrt(lamb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6421561248852019"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(w_thalf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2022892993910377"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1/np.sqrt(lamb)) / np.linalg.norm(w_thalf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2022892993910377"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/ (np.sqrt(lamb) * np.linalg.norm(w_thalf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(1, (1/np.sqrt(lamb)) / np.linalg.norm(w_thalf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01679521]\n",
      " [0.02267094]\n",
      " [0.02501692]\n",
      " [0.02257767]\n",
      " [0.01720586]]\n",
      "[[0.01679521]\n",
      " [0.02267094]\n",
      " [0.02501692]\n",
      " [0.02257767]\n",
      " [0.01720586]]\n"
     ]
    }
   ],
   "source": [
    "print(w[100:105])\n",
    "print((min(1, (1/np.sqrt(lamb)) / np.linalg.norm(w_thalf)) * w_thalf)[100:105])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.452827134166708\n",
      "10.093860011067788\n",
      "9.835141338468135\n",
      "9.52079422491376\n",
      "9.123179328476454\n",
      "7.967919767320386\n",
      "3.834729179982926\n",
      "7.424633619801147\n",
      "3.7109550311303727\n",
      "3.970824405064623\n",
      "6.228623595507413\n",
      "1.6010225271473437\n",
      "2.6696505234322143\n",
      "3.5541802964761318\n",
      "2.641641581393384\n",
      "3.5489322847221443\n",
      "1.778074392722976\n",
      "1.8237124376081097\n",
      "1.5607199219485512\n",
      "1.7360603293035948\n",
      "1.100557432258906\n",
      "0.9773939716254765\n",
      "0.9567473471736523\n",
      "1.00469224802512\n",
      "1.8652277122917182\n",
      "1.8741820286804072\n",
      "1.4114773722236196\n",
      "1.0536749985158365\n",
      "0.8547114841829636\n",
      "0.7573139617410625\n",
      "0.8298599709493593\n",
      "0.6936125949527677\n",
      "0.634243245090607\n",
      "0.6258387324765406\n",
      "0.70861291756583\n",
      "0.68346725683966\n",
      "0.8297838754596786\n",
      "1.1789130059725867\n",
      "1.0799952466287794\n",
      "1.334959892664736\n",
      "0.6718312786430252\n",
      "0.6922535363499542\n",
      "0.6342383974367013\n",
      "0.5978739262469516\n",
      "0.5795316965426077\n",
      "0.6189877317888699\n",
      "0.5900312766163833\n",
      "0.8571726957607114\n",
      "1.0981010368594668\n",
      "0.856580010531027\n",
      "0.7002875252109071\n",
      "0.7766549706401328\n",
      "0.8454275951292964\n",
      "0.7009480903686967\n",
      "0.6356600079771423\n",
      "0.666270053268601\n",
      "0.609093808550013\n",
      "0.703491394140122\n",
      "0.89249469498188\n",
      "0.6725245612268117\n",
      "0.8758376159485818\n",
      "0.6848207686917286\n",
      "0.7833395771598689\n",
      "0.6073939899503862\n",
      "0.6212251948579903\n",
      "0.5622641584784445\n",
      "0.5740608335670275\n",
      "0.5491112855098856\n",
      "0.5386692628649614\n",
      "0.5446276648512802\n",
      "0.5516033992009683\n",
      "0.6557332860696691\n",
      "0.6032115190620532\n",
      "0.5326176439583077\n",
      "0.5436791456008687\n",
      "0.5380535236619571\n",
      "0.6107055373168011\n",
      "0.718311131265182\n",
      "0.7093392528001268\n",
      "0.5518913832674468\n",
      "0.5638341887243724\n",
      "0.5899658821204482\n",
      "0.5815506590389772\n",
      "0.5287094247243224\n",
      "0.53232696610149\n",
      "0.5238384923867002\n",
      "0.567517069458747\n",
      "0.5554631363878659\n",
      "0.5193810924677857\n",
      "0.5204017018036847\n",
      "0.5185602651426975\n",
      "0.5792238533813845\n",
      "0.5220574159442722\n",
      "0.5200412819090496\n",
      "0.5304974410642055\n",
      "0.5173365849567342\n",
      "0.5215847393509353\n",
      "0.6054870962735924\n",
      "0.5240608572806962\n",
      "0.5551524831456439\n",
      "0.6067625479756391\n",
      "0.6333760606057275\n",
      "0.5377485489631922\n",
      "0.518512737072298\n",
      "0.5305624755216901\n",
      "0.5263655994275653\n",
      "0.5271341486765772\n",
      "0.5172090331658687\n",
      "0.5168627872553659\n",
      "0.5165446914166756\n",
      "0.5179800612901498\n",
      "0.5352128269682587\n",
      "0.5804601172702194\n",
      "0.5436653688556226\n",
      "0.5215518931276228\n",
      "0.5339881961511658\n",
      "0.585809738465947\n",
      "0.5177113295515183\n",
      "0.5273380671153935\n",
      "0.5172958062880064\n",
      "0.553900590579135\n",
      "0.518002343718173\n",
      "0.5163905567783276\n",
      "0.5298763319370086\n",
      "0.5161195132635408\n",
      "0.5160958948373544\n",
      "0.5223802377618328\n",
      "0.5175384880918895\n",
      "0.5163811789191257\n",
      "0.5465534363541319\n",
      "0.5716749978096828\n",
      "0.5213453048942285\n",
      "0.5166205664141722\n",
      "0.5233815231107593\n",
      "0.5137023409983728\n",
      "0.5191367181048208\n",
      "0.5308723344806465\n",
      "0.5204588391422849\n",
      "0.5145150170190848\n",
      "0.5185970213356252\n",
      "0.5144393205186526\n",
      "0.5256334452242523\n",
      "0.5251770147102135\n",
      "0.5312424079972887\n",
      "0.5230324505115967\n",
      "0.5131595137575637\n",
      "0.5116699387522013\n",
      "0.5115623250889301\n",
      "0.5204524703994786\n",
      "0.5268927985688562\n",
      "0.5117011460119433\n",
      "0.5137898520694513\n",
      "0.5442009194595553\n",
      "0.535687827350749\n",
      "0.5198805690956593\n",
      "0.5139820513858608\n",
      "0.5326618628829247\n",
      "0.5161864216453705\n",
      "0.5170100627562733\n",
      "0.5118577880097238\n",
      "0.5207914111248881\n",
      "0.5103574293644931\n",
      "0.51655764058958\n",
      "0.5131767728980565\n",
      "0.5115712954026813\n",
      "0.5343143826323168\n",
      "0.5192652287479108\n",
      "0.5112872679157965\n",
      "0.5102913879910379\n",
      "0.5115270627750936\n",
      "0.520916799563872\n",
      "0.5100493185978121\n",
      "0.5141547066632808\n",
      "0.513127258865411\n",
      "0.5093612856662473\n",
      "0.5160084376332578\n",
      "0.5123848994467117\n",
      "0.5130827280092879\n",
      "0.5103407835615827\n",
      "0.5148693405567949\n",
      "0.5212941525201256\n",
      "0.5236788212227017\n",
      "0.509738729722425\n",
      "0.5131844301184781\n",
      "0.5094333361021919\n",
      "0.5117679894120881\n",
      "0.5133030208565463\n",
      "0.5108723260814755\n",
      "0.5198873425121913\n",
      "0.5124465879753177\n",
      "0.5124503700950196\n",
      "0.5160489861981014\n",
      "0.5193082837535212\n",
      "0.5178334366758746\n",
      "0.5098145641668534\n",
      "0.5140648087046148\n",
      "0.5099478572556193\n",
      "0.5123109860527003\n",
      "0.5160625698471114\n",
      "0.513119712636686\n",
      "0.5145128453077255\n",
      "0.5107688888193338\n",
      "0.5235441953458795\n",
      "0.5117464076875593\n",
      "0.513910803742362\n",
      "0.5128529111841816\n",
      "0.5122207872769962\n",
      "0.5113497646305061\n",
      "0.5123410579875564\n",
      "0.5198216182282215\n",
      "0.5118967114615325\n",
      "0.5189928371479461\n",
      "0.5112073258000591\n",
      "0.5115309179427823\n",
      "0.5157436078120461\n",
      "0.5100162562926265\n",
      "0.5243902331915369\n",
      "0.5183850854965453\n",
      "0.5134353615390042\n",
      "0.5099751644596128\n",
      "0.5101148123464849\n",
      "0.5088387054213348\n",
      "0.5104663168234181\n",
      "0.5144361204154408\n",
      "0.5327983282510961\n",
      "0.5210302718027435\n",
      "0.5088698011718077\n",
      "0.5093953000053772\n",
      "0.511342374289954\n",
      "0.5092131718604391\n",
      "0.5089569458902409\n",
      "0.508143792536758\n",
      "0.5089886484660757\n",
      "0.5113814870380986\n",
      "0.508428914271527\n",
      "0.5094215281111328\n",
      "0.5144648294152824\n",
      "0.5081275488873076\n",
      "0.5080990066968053\n",
      "0.5189699186000488\n",
      "0.5117458989821603\n",
      "0.5084229600134381\n",
      "0.5124247056745573\n",
      "0.5079702040538352\n",
      "0.5076002579216871\n",
      "0.5098803526456884\n",
      "0.5079970282184928\n",
      "0.5073183435660091\n",
      "0.5074589751570894\n",
      "0.509218572263015\n",
      "0.5120394164013927\n",
      "0.5080257459651584\n",
      "0.5173956995312149\n",
      "0.5110762508184364\n",
      "0.5334950127908136\n",
      "0.5235725287988418\n",
      "0.508072168315031\n",
      "0.509330247755034\n",
      "0.5231426399485921\n",
      "0.5120857713071243\n",
      "0.5132897819378451\n",
      "0.5092149354793143\n",
      "0.5160879685577558\n",
      "0.5086916098162708\n",
      "0.5070074412535891\n",
      "0.5105204975867619\n",
      "0.5098951832187699\n",
      "0.508205612382861\n",
      "0.5093482069577908\n",
      "0.510348658719695\n",
      "0.5087992055891338\n",
      "0.5086353842789862\n",
      "0.5084432139474563\n",
      "0.5096881899622417\n",
      "0.5115143737699297\n",
      "0.5107220687887966\n",
      "0.5171809946382736\n",
      "0.5089432615860215\n",
      "0.5101447215123062\n",
      "0.5081634695320068\n",
      "0.5062033725753453\n",
      "0.5065958257678288\n",
      "0.5064098264051621\n",
      "0.5097674225408274\n",
      "0.5175754004370723\n",
      "0.5072855445733502\n",
      "0.5092755742846503\n",
      "0.5142526974252803\n",
      "0.5080998615959891\n",
      "0.508524118435159\n",
      "0.5064903794317936\n",
      "0.5075097104305553\n",
      "0.5069066116040735\n",
      "0.5140567478224868\n",
      "0.5099612501542874\n",
      "0.5117450653795151\n",
      "0.5129985783106225\n",
      "0.5067577759545865\n",
      "0.5066486353517287\n",
      "0.5065073330726169\n",
      "0.5071833329134768\n",
      "0.5070452638255332\n",
      "0.5071709950849752\n",
      "0.5107176953612843\n",
      "0.5071683417387569\n",
      "0.5185013221391842\n",
      "0.5069507336620264\n",
      "0.5071230076323023\n",
      "0.509412213625976\n",
      "0.5153064995823756\n",
      "0.5068681672374558\n",
      "0.5086831870197982\n",
      "0.510987643572768\n",
      "0.5070591035256271\n",
      "0.5068175976882927\n",
      "0.506483244820251\n",
      "0.5068986867022974\n",
      "0.5069718968813749\n",
      "0.5065169322588973\n",
      "0.5154192541740147\n",
      "0.5170774612784055\n",
      "0.5101797399297724\n",
      "0.5069717048079191\n",
      "0.507251988150356\n",
      "0.5063335147461419\n",
      "0.5174859417571884\n",
      "0.5065430035564278\n",
      "0.5073398623816806\n",
      "0.5104973901441003\n",
      "0.5072403906042429\n",
      "0.5068582710652485\n",
      "0.5158992632660857\n",
      "0.5171659498035238\n",
      "0.5070053017275982\n",
      "0.5068650132570226\n",
      "0.508955009058033\n",
      "0.5090984197602384\n",
      "0.507706720962364\n",
      "0.5080606380730205\n",
      "0.506453919776587\n",
      "0.5071212646085347\n",
      "0.5099950128747207\n",
      "0.507371053371893\n",
      "0.5066757844958394\n",
      "0.506672595923486\n",
      "0.5065216059437985\n",
      "0.5071354361694893\n",
      "0.5155003019643023\n",
      "0.5070236927134188\n",
      "0.5076159854991887\n",
      "0.5145540599439719\n",
      "0.5174778548611192\n",
      "0.5064979283661106\n",
      "0.5105383129606424\n",
      "0.5061083922678749\n",
      "0.5087805373444633\n",
      "0.5124631692669164\n",
      "0.5065723333888417\n",
      "0.5064304518352615\n",
      "0.5065728929706285\n",
      "0.5073521477392371\n",
      "0.5065926286288742\n",
      "0.5060953628103829\n",
      "0.5068195417968631\n",
      "0.5060012841582602\n",
      "0.5059902624726426\n",
      "0.5085598113566848\n",
      "0.5066788117575441\n",
      "0.5060393939915422\n",
      "0.5078664464012894\n",
      "0.5126512700269622\n",
      "0.5109679674310901\n",
      "0.5083445738341051\n",
      "0.5066716810104476\n",
      "0.5058835045183622\n",
      "0.5063589337295403\n",
      "0.5060522577683797\n",
      "0.5063905462791444\n",
      "0.5113385999574414\n",
      "0.513238011537506\n",
      "0.5154263120137396\n",
      "0.5206723275533419\n",
      "0.506577133062814\n",
      "0.5092841550924246\n",
      "0.5065161054948675\n",
      "0.5064967352013732\n",
      "0.5062509310515718\n",
      "0.5061466845791313\n",
      "0.5065897032054176\n",
      "0.5059540925117885\n",
      "0.5062609587931381\n",
      "0.506217237162118\n",
      "0.5089337498193399\n",
      "0.5062575282932298\n",
      "0.5064400385924069\n",
      "0.5062597200570659\n",
      "0.5058708041028218\n",
      "0.5058819933004767\n",
      "0.5061358962214841\n",
      "0.5062484017298576\n",
      "0.5068604607030166\n",
      "0.5110751238284253\n",
      "0.5069984260574062\n",
      "0.5121156517356381\n",
      "0.5062654943715958\n",
      "0.5067830803410002\n",
      "0.509312181420284\n",
      "0.5060125939951201\n",
      "0.5063299541969485\n",
      "0.5065336605075611\n",
      "0.5065152655144693\n",
      "0.5119722387571624\n",
      "0.5069622878967796\n",
      "0.5063018081532346\n",
      "0.5064136693041006\n",
      "0.5069689935577169\n",
      "0.5066670014382083\n",
      "0.5071442066698818\n",
      "0.5069926191724228\n",
      "0.507913073830249\n",
      "0.506427065309017\n",
      "0.5068333009394198\n",
      "0.5106180025670471\n",
      "0.5148573772534181\n",
      "0.5083259511474799\n",
      "0.507423191399856\n",
      "0.5078864891923224\n",
      "0.5071350139817952\n",
      "0.5063671460214952\n",
      "0.5061100967930466\n",
      "0.5061601621786163\n",
      "0.505966482375868\n",
      "0.5075988116761719\n",
      "0.5089692703468944\n",
      "0.5064316190189956\n",
      "0.5066433780804137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5066192487840776\n",
      "0.5067649146573753\n",
      "0.5056632344430416\n",
      "0.505720429116956\n",
      "0.5063782941201129\n",
      "0.5095309537774733\n",
      "0.5066137810033269\n",
      "0.5060554208017738\n",
      "0.5067536824741422\n",
      "0.5053595470815793\n",
      "0.5060754896069308\n",
      "0.5053972826603366\n",
      "0.5052487848477204\n",
      "0.5053635550347958\n",
      "0.5113542714053073\n",
      "0.506251250341551\n",
      "0.5052656776733236\n",
      "0.5057175369813725\n",
      "0.5058309736434352\n",
      "0.5072880801796926\n",
      "0.5059595555497989\n",
      "0.5065684483834755\n",
      "0.5068172545501779\n",
      "0.5070111604133404\n",
      "0.5055301408589424\n",
      "0.5069736011983528\n",
      "0.5057627208481658\n",
      "0.5075974042755259\n",
      "0.505851677873884\n",
      "0.5062209795383785\n",
      "0.507598269537332\n",
      "0.5055483103060581\n",
      "0.5060579499542928\n",
      "0.5061234982095324\n",
      "0.5133616361614832\n",
      "0.5053798035275763\n",
      "0.5093244050758514\n",
      "0.5112258724546079\n",
      "0.5067881553156678\n",
      "0.5055332705744477\n",
      "0.5058403038986727\n",
      "0.5077611761658118\n",
      "0.5121825655857493\n",
      "0.5056276130064528\n",
      "0.5056213151175778\n",
      "0.5063169932451\n",
      "0.5051484282022937\n",
      "0.5072458272955291\n",
      "0.5053188801263806\n",
      "0.5066540514318111\n",
      "0.5121197603690943\n",
      "0.514278171428997\n",
      "0.5105818317259098\n",
      "0.5075826534077688\n",
      "0.5059952257937358\n",
      "0.5062705965815388\n",
      "0.5056305833300463\n",
      "0.505551858841181\n",
      "0.5071067752101672\n",
      "0.5058217087269091\n",
      "0.5057317057624506\n",
      "0.5058800390970796\n",
      "0.5064731426458026\n",
      "0.5091690979679783\n"
     ]
    }
   ],
   "source": [
    "    max_iterations = 500\n",
    "    k = 100\n",
    "    lamb = 0.1\n",
    "    w = np.zeros((len(Xtrain[0]), 1))\n",
    "    w_l, train_obj= pegasos_train(Xtrain, ytrain, w, lamb, k, max_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"\"\"\n",
    "    Inputs:\n",
    "    - Xtest: A list of num_test elements, where each element is a list of D-dimensional features.\n",
    "    - ytest: A list of num_test labels\n",
    "    - w_l: a numpy array of D elements as a D-dimension vector, which is the weight vector of SVM classifier and learned by pegasos_train()\n",
    " \n",
    "    Returns:\n",
    "    - test_acc: testing accuracy.\n",
    "    \"\"\"\n",
    "    # you need to fill in your solution here\n",
    "    Xtest = np.array(Xtest)\n",
    "    ytest = np.array(ytest)\n",
    "    N = Xtest.shape[0]\n",
    "    #ywx = (np.multiply(ytest, np.transpose(np.dot(Xtest,w_l))) > 0).ravel()\n",
    "    #ywx = np.sign((np.multiply(ytest, np.transpose(np.dot(Xtest,w_l)))).ravel())\n",
    "    wx = np.sign(np.dot(Xtest, w_l).ravel())\n",
    "    #ytru = ytest > 0\n",
    "    #test_acc = sum(ytru == ywx)/N\n",
    "    test_acc = np.sum(ytest.ravel() == wx)/N\n",
    "\n",
    "\n",
    "    #return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(785, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 785)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 * (np.dot(Xtest, w_l)>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1000)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest.ravel().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "814"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(ytest.ravel() == wx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True, False,  True,  True, False,  True, False, False,\n",
       "         True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "         True,  True, False, False, False,  True,  True,  True,  True,\n",
       "        False,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "         True,  True, False, False,  True,  True, False,  True, False,\n",
       "         True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False, False,  True,  True,  True,  True,  True, False,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True, False,  True, False, False,  True,  True,  True,\n",
       "         True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True, False, False,  True,  True,  True,  True,\n",
       "        False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True, False,  True,  True,  True,  True, False, False,\n",
       "         True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True, False, False,  True,  True,  True,  True, False,\n",
       "         True,  True, False,  True, False, False,  True, False,  True,\n",
       "         True,  True,  True,  True,  True, False,  True,  True, False,\n",
       "         True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "         True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True, False,  True,  True, False,  True,  True,\n",
       "         True,  True,  True, False,  True,  True,  True,  True, False,\n",
       "         True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "         True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "         True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "         True, False, False,  True,  True,  True, False,  True,  True,\n",
       "         True,  True,  True,  True,  True, False, False, False,  True,\n",
       "         True,  True,  True,  True,  True, False,  True, False,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "         True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "         True,  True, False,  True,  True, False,  True,  True, False,\n",
       "         True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "         True,  True,  True,  True, False, False,  True,  True,  True,\n",
       "        False,  True,  True,  True,  True, False, False,  True, False,\n",
       "         True,  True,  True,  True,  True, False,  True, False,  True,\n",
       "        False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "         True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "         True,  True,  True, False,  True,  True, False,  True,  True,\n",
       "        False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "         True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False,  True,  True,  True,  True, False,  True, False,  True,\n",
       "         True, False,  True,  True, False,  True,  True,  True,  True,\n",
       "         True, False,  True,  True, False,  True,  True,  True, False,\n",
       "         True, False,  True, False,  True, False,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "         True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True, False,  True, False,  True, False,\n",
       "         True,  True,  True,  True, False,  True,  True,  True, False,\n",
       "         True,  True,  True,  True,  True, False,  True,  True, False,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "        False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "         True,  True,  True,  True,  True, False, False, False,  True,\n",
       "        False,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "        False, False,  True, False, False,  True,  True,  True,  True,\n",
       "         True, False,  True,  True,  True,  True,  True, False, False,\n",
       "         True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True, False,  True, False, False, False,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "        False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "         True,  True, False,  True,  True,  True,  True, False,  True,\n",
       "         True,  True, False,  True, False,  True,  True,  True,  True,\n",
       "         True,  True, False,  True, False,  True,  True,  True, False,\n",
       "         True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        False,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "        False,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "        False,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True, False, False,  True, False,  True,  True, False,  True,\n",
       "         True, False,  True,  True, False, False,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True, False,  True,  True, False,\n",
       "         True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "         True,  True, False, False, False,  True,  True,  True,  True,\n",
       "        False,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "        False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False,  True,  True,  True,  True, False,  True, False,  True,\n",
       "         True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "        False,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "         True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "         True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "         True,  True,  True,  True,  True,  True, False, False, False,\n",
       "         True, False,  True,  True,  True, False,  True, False,  True,\n",
       "         True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "         True, False,  True, False,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True, False,  True,  True, False,  True, False,\n",
       "        False]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest.reshape((1, ytest.shape[0])) == wx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1., -1.,  1., -1., -1., -1.,  1.,  1.,  1., -1.,  1., -1.,\n",
       "       -1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1., -1., -1.,\n",
       "        1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1.,\n",
       "        1.,  1., -1., -1.,  1., -1.,  1.,  1.,  1.,  1., -1., -1.,  1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1., -1.,\n",
       "       -1.,  1.,  1., -1., -1., -1.,  1., -1., -1.,  1.,  1.,  1., -1.,\n",
       "        1.,  1., -1., -1., -1.,  1., -1.,  1.,  1.,  1., -1., -1.,  1.,\n",
       "        1.,  1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1.,\n",
       "        1., -1.,  1., -1.,  1., -1., -1.,  1.,  1., -1.,  1., -1.,  1.,\n",
       "       -1., -1.,  1., -1., -1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,\n",
       "       -1., -1.,  1., -1., -1., -1., -1., -1.,  1., -1., -1.,  1., -1.,\n",
       "       -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1.,\n",
       "       -1.,  1., -1., -1., -1.,  1.,  1., -1., -1.,  1.,  1.,  1., -1.,\n",
       "       -1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1., -1.,  1., -1., -1.,\n",
       "       -1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1.,\n",
       "        1., -1.,  1., -1.,  1., -1., -1., -1.,  1.,  1.,  1., -1.,  1.,\n",
       "        1.,  1.,  1., -1., -1., -1., -1.,  1.,  1.,  1.,  1., -1., -1.,\n",
       "        1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,\n",
       "       -1.,  1., -1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1., -1.,  1.,\n",
       "       -1., -1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1., -1.,  1.,\n",
       "        1., -1.,  1., -1.,  1., -1.,  1.,  1.,  1., -1., -1.,  1., -1.,\n",
       "       -1.,  1., -1., -1., -1.,  1., -1.,  1.,  1., -1., -1.,  1.,  1.,\n",
       "        1., -1., -1.,  1., -1.,  1., -1., -1., -1.,  1., -1.,  1., -1.,\n",
       "        1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1.,  1.,  1., -1., -1.,\n",
       "       -1., -1.,  1., -1., -1.,  1.,  1., -1., -1.,  1.,  1.,  1., -1.,\n",
       "        1.,  1.,  1., -1., -1., -1.,  1., -1.,  1., -1.,  1.,  1.,  1.,\n",
       "       -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,\n",
       "        1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,\n",
       "       -1., -1.,  1.,  1.,  1., -1.,  1.,  1., -1., -1., -1., -1.,  1.,\n",
       "        1.,  1., -1.,  1., -1.,  1.,  1., -1., -1., -1.,  1., -1.,  1.,\n",
       "       -1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1., -1., -1., -1.,  1.,\n",
       "       -1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1., -1.,  1.,  1., -1.,\n",
       "       -1., -1.,  1., -1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1., -1.,\n",
       "       -1., -1., -1.,  1.,  1.,  1., -1., -1., -1., -1.,  1.,  1., -1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1., -1., -1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1., -1.,  1., -1.,  1.,\n",
       "       -1.,  1., -1.,  1.,  1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1.,\n",
       "        1., -1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1., -1., -1.,  1.,\n",
       "       -1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1., -1.,\n",
       "        1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,\n",
       "        1.,  1., -1.,  1., -1., -1., -1., -1.,  1., -1., -1.,  1., -1.,\n",
       "       -1.,  1., -1., -1., -1., -1.,  1.,  1.,  1.,  1., -1., -1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1., -1., -1.,  1., -1.,  1., -1., -1.,  1.,\n",
       "       -1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1.,  1., -1., -1.,  1.,\n",
       "        1.,  1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1., -1.,\n",
       "       -1.,  1.,  1.,  1., -1.,  1., -1., -1., -1., -1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1.,  1., -1.,  1.,\n",
       "        1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
       "        1.,  1.,  1., -1., -1., -1., -1., -1.,  1.,  1.,  1., -1., -1.,\n",
       "        1., -1.,  1., -1., -1., -1.,  1.,  1., -1., -1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1., -1.,  1.,  1., -1., -1.,  1., -1., -1., -1., -1.,\n",
       "        1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1., -1.,\n",
       "        1., -1.,  1., -1.,  1., -1.,  1., -1.,  1., -1., -1.,  1., -1.,\n",
       "        1.,  1.,  1., -1., -1.,  1., -1., -1., -1.,  1., -1., -1., -1.,\n",
       "        1., -1.,  1.,  1., -1., -1.,  1.,  1., -1., -1., -1.,  1., -1.,\n",
       "        1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1., -1., -1.,  1.,  1.,\n",
       "        1., -1., -1., -1., -1., -1., -1., -1.,  1., -1.,  1., -1.,  1.,\n",
       "       -1., -1.,  1., -1., -1., -1.,  1., -1., -1., -1., -1.,  1.,  1.,\n",
       "       -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1.,\n",
       "       -1.,  1.,  1.,  1., -1.,  1., -1., -1.,  1.,  1., -1., -1.,  1.,\n",
       "        1.,  1.,  1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1.,  1., -1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1.,  1., -1.,\n",
       "        1.,  1., -1., -1.,  1.,  1., -1.,  1., -1., -1.,  1.,  1.,  1.,\n",
       "       -1., -1.,  1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1.,  1., -1.,\n",
       "        1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,\n",
       "        1.,  1., -1., -1., -1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  1.,\n",
       "        1.,  1., -1., -1., -1., -1., -1., -1., -1.,  1.,  1.,  1.,  1.,\n",
       "       -1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1.,\n",
       "        1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1., -1., -1.,  1.,\n",
       "        1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1., -1., -1., -1., -1., -1., -1.,  1.,  1.,  1.,  1., -1.,\n",
       "       -1.,  1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1., -1., -1.,\n",
       "        1.,  1.,  1., -1., -1., -1., -1., -1., -1., -1.,  1., -1., -1.,\n",
       "        1.,  1.,  1., -1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1.,  1.,\n",
       "        1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1., -1.,\n",
       "        1., -1., -1.,  1., -1., -1.,  1.,  1.,  1., -1., -1.,  1.,  1.,\n",
       "        1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sign(np.dot(Xtest, w_l).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.001, 0.   , 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "       0.001, 0.001, 0.   , 0.001, 0.001, 0.   , 0.001, 0.   , 0.   ,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.001, 0.   , 0.001, 0.001, 0.001,\n",
       "       0.001, 0.001, 0.   , 0.   , 0.   , 0.001, 0.001, 0.001, 0.001,\n",
       "       0.   , 0.001, 0.001, 0.   , 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "       0.001, 0.001, 0.   , 0.   , 0.001, 0.001, 0.   , 0.001, 0.   ,\n",
       "       0.001, 0.   , 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "       0.   , 0.   , 0.001, 0.001, 0.001, 0.001, 0.001, 0.   , 0.001,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "       0.001, 0.001, 0.   , 0.001, 0.   , 0.   , 0.001, 0.001, 0.001,\n",
       "       0.001, 0.   , 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "       0.001, 0.001, 0.001, 0.   , 0.   , 0.001, 0.001, 0.001, 0.001,\n",
       "       0.   , 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "       0.001, 0.001, 0.   , 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "       0.001, 0.001, 0.   , 0.001, 0.001, 0.001, 0.001, 0.   , 0.   ,\n",
       "       0.001, 0.   , 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "       0.001, 0.001, 0.   , 0.   , 0.001, 0.001, 0.001, 0.001, 0.   ,\n",
       "       0.001, 0.001, 0.   , 0.001, 0.   , 0.   , 0.001, 0.   , 0.001,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.001, 0.   , 0.001, 0.001, 0.   ,\n",
       "       0.001, 0.001, 0.001, 0.   , 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "       0.001, 0.001, 0.001, 0.   , 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.   , 0.001, 0.001, 0.001, 0.001,\n",
       "       0.001, 0.001, 0.   , 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.   , 0.001, 0.001, 0.001, 0.001,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.001, 0.   , 0.001, 0.001, 0.001,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "       0.001, 0.001, 0.001, 0.   , 0.001, 0.001, 0.   , 0.001, 0.001,\n",
       "       0.001, 0.001, 0.001, 0.   , 0.001, 0.001, 0.001, 0.001, 0.   ,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.   , 0.001, 0.001,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.001, 0.   , 0.001, 0.001, 0.001,\n",
       "       0.001, 0.   , 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.001, 0.   , 0.001, 0.001, 0.001,\n",
       "       0.001, 0.   , 0.   , 0.001, 0.001, 0.001, 0.   , 0.001, 0.001,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.001, 0.   , 0.   , 0.   , 0.001,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.001, 0.   , 0.001, 0.   , 0.001,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.   , 0.001,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.   , 0.001, 0.001, 0.001, 0.001,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.   , 0.001, 0.001,\n",
       "       0.001, 0.001, 0.   , 0.001, 0.001, 0.   , 0.001, 0.001, 0.   ,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.001, 0.   , 0.001, 0.001, 0.001,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.   , 0.   , 0.001, 0.001, 0.001,\n",
       "       0.   , 0.001, 0.001, 0.001, 0.001, 0.   , 0.   , 0.001, 0.   ,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.001, 0.   , 0.001, 0.   , 0.001,\n",
       "       0.   , 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.   , 0.001,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.   , 0.001,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.   , 0.001, 0.001, 0.001, 0.001,\n",
       "       0.001, 0.001, 0.001, 0.   , 0.001, 0.001, 0.   , 0.001, 0.001,\n",
       "       0.   , 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "       0.   , 0.001, 0.001, 0.001, 0.   , 0.001, 0.001, 0.001, 0.001,\n",
       "       0.001, 0.   , 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "       0.   , 0.001, 0.001, 0.001, 0.001, 0.   , 0.001, 0.   , 0.001,\n",
       "       0.001, 0.   , 0.001, 0.001, 0.   , 0.001, 0.001, 0.001, 0.001,\n",
       "       0.001, 0.   , 0.001, 0.001, 0.   , 0.001, 0.001, 0.001, 0.   ,\n",
       "       0.001, 0.   , 0.001, 0.   , 0.001, 0.   , 0.001, 0.001, 0.001,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.   ,\n",
       "       0.001, 0.001, 0.001, 0.   , 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.   , 0.001, 0.   , 0.001, 0.   ,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.   , 0.001, 0.001, 0.001, 0.   ,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.001, 0.   , 0.001, 0.001, 0.   ,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.   , 0.001,\n",
       "       0.   , 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.   ,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.001, 0.   , 0.   , 0.   , 0.001,\n",
       "       0.   , 0.001, 0.001, 0.001, 0.   , 0.001, 0.001, 0.001, 0.001,\n",
       "       0.   , 0.   , 0.001, 0.   , 0.   , 0.001, 0.001, 0.001, 0.001,\n",
       "       0.001, 0.   , 0.001, 0.001, 0.001, 0.001, 0.001, 0.   , 0.   ,\n",
       "       0.001, 0.   , 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "       0.001, 0.   , 0.001, 0.   , 0.   , 0.   , 0.001, 0.001, 0.001,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "       0.001, 0.001, 0.   , 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "       0.   , 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.   , 0.001, 0.001,\n",
       "       0.001, 0.001, 0.   , 0.001, 0.001, 0.001, 0.001, 0.   , 0.001,\n",
       "       0.001, 0.001, 0.   , 0.001, 0.   , 0.001, 0.001, 0.001, 0.001,\n",
       "       0.001, 0.001, 0.   , 0.001, 0.   , 0.001, 0.001, 0.001, 0.   ,\n",
       "       0.001, 0.001, 0.001, 0.   , 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "       0.   , 0.001, 0.001, 0.001, 0.   , 0.001, 0.001, 0.001, 0.001,\n",
       "       0.   , 0.001, 0.001, 0.001, 0.001, 0.   , 0.001, 0.001, 0.001,\n",
       "       0.   , 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.   , 0.001,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "       0.001, 0.   , 0.   , 0.001, 0.   , 0.001, 0.001, 0.   , 0.001,\n",
       "       0.001, 0.   , 0.001, 0.001, 0.   , 0.   , 0.001, 0.001, 0.001,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.   , 0.001, 0.001,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.   , 0.001,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.001, 0.   , 0.001, 0.001, 0.   ,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.   , 0.001, 0.001,\n",
       "       0.001, 0.001, 0.   , 0.   , 0.   , 0.001, 0.001, 0.001, 0.001,\n",
       "       0.   , 0.001, 0.001, 0.001, 0.001, 0.001, 0.   , 0.001, 0.001,\n",
       "       0.   , 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "       0.   , 0.001, 0.001, 0.001, 0.001, 0.   , 0.001, 0.   , 0.001,\n",
       "       0.001, 0.001, 0.   , 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.001, 0.   , 0.001, 0.001, 0.001,\n",
       "       0.   , 0.001, 0.001, 0.001, 0.001, 0.   , 0.001, 0.001, 0.001,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.   , 0.001, 0.001,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.001, 0.   , 0.001, 0.001, 0.001,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.   , 0.001, 0.001, 0.001, 0.001,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.   , 0.001,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.   , 0.   , 0.   ,\n",
       "       0.001, 0.   , 0.001, 0.001, 0.001, 0.   , 0.001, 0.   , 0.001,\n",
       "       0.001, 0.001, 0.001, 0.   , 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "       0.001, 0.   , 0.001, 0.   , 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "       0.001, 0.001, 0.001, 0.   , 0.001, 0.001, 0.   , 0.001, 0.   ,\n",
       "       0.   ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.multiply(ytest, np.transpose(np.dot(Xtest,w_l))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ywx = (np.multiply(ytest, np.transpose(np.dot(Xtest,w_l))) > 0).ravel()\n",
    "ytru = ytest > 0\n",
    "sum(ytru * 1 == ywx * 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytru*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yytr=[True, True, False, False]\n",
    "yyte=[True, False, False, False]\n",
    "type(yyte)\n",
    "#sum(yytr == yyte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= np.array([1,2]) > 1\n",
    "b = np.array([[-1],[2]])>0\n",
    "a==b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a==np.transpose(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ywx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = np.array([[1,1],[1,0],[0,1],[-1,-1]])\n",
    "wg = np.array([[2],[4]])\n",
    "np.dot(g,wg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convergence curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader_pegasos(dataset):\n",
    "\n",
    "    with open(dataset, 'r') as f:\n",
    "            data_set = json.load(f)\n",
    "    train_set, valid_set, test_set = data_set['train'], data_set['valid'], data_set['test']\n",
    "\n",
    "    Xtrain = train_set[0]\n",
    "    ytrain = train_set[1]\n",
    "    Xvalid = valid_set[0]\n",
    "    yvalid = valid_set[1]\n",
    "    Xtest = test_set[0]\n",
    "    ytest = test_set[1]\n",
    "\n",
    "    ## below we add 'one' to the feature of each sample, such that we include the bias term into parameter w\n",
    "    Xtrain = np.hstack((np.ones((len(Xtrain), 1)), np.array(Xtrain))).tolist()\n",
    "    Xvalid = np.hstack((np.ones((len(Xvalid), 1)), np.array(Xvalid))).tolist()\n",
    "    Xtest = np.hstack((np.ones((len(Xtest), 1)), np.array(Xtest))).tolist()\n",
    "\n",
    "    for i, v in enumerate(ytrain):\n",
    "        if v < 5:\n",
    "            ytrain[i] = -1.\n",
    "        else:\n",
    "            ytrain[i] = 1.\n",
    "    for i, v in enumerate(ytest):\n",
    "        if v < 5:\n",
    "            ytest[i] = -1.\n",
    "        else:\n",
    "            ytest[i] = 1.\n",
    "\n",
    "    return Xtrain, ytrain, Xvalid, yvalid, Xtest, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'pegasos.json'\n",
    "with open(dataset, 'r') as f:\n",
    "    data_set = json.load(f)\n",
    "a = data_set[0]['k=10_lambda=0.1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_ = data_set[0]['k=10_lambda=0.1']\n",
    "obj_ = data_set[1]['k=10_lambda=0.1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'k=100_lambda=0.01': 0.65,\n",
       " 'k=100_lambda=0.1': 0.568,\n",
       " 'k=100_lambda=1': 0.564,\n",
       " 'k=1_lambda=0.1': 0.555,\n",
       " 'k=10_lambda=0.1': 0.584,\n",
       " 'k=1000_lambda=0.1': 0.548}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x200316f4c88>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "obj_1 = data_set[1]['k=100_lambda=0.01']\n",
    "plt.plot(range(len(obj_1)) , obj_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x200342f16d8>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "obj_2 = data_set[1]['k=100_lambda=0.1']\n",
    "plt.plot(range(len(obj_2)) , obj_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20034357470>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "obj_3 = data_set[1]['k=100_lambda=1']\n",
    "plt.plot(range(len(obj_3)) , obj_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
