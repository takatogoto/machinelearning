{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "###### Q1.1 ######\n",
    "def objective_function(X, y, w, lamb):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    - Xtrain: A 2 dimensional numpy array of data (number of samples x number of features)\n",
    "    - ytrain: A 1 dimensional numpy array of labels (length = number of samples )\n",
    "    - w: a numpy array of D elements as a D-dimension weight vector\n",
    "    - lamb: lambda used in pegasos algorithm\n",
    "\n",
    "    Return:\n",
    "    - obj_value: the value of objective function in SVM primal formulation\n",
    "    \"\"\"\n",
    "    # you need to fill in your solution here\n",
    "    \n",
    "    # 0.5 * lamb * ||w||^2 + 1/N sum(max(0,1-ywx))  \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    N = X.shape[0]\n",
    "    z = 1- np.multiply(y, np.transpose(np.dot(X,w)))\n",
    "    zmax = z[z>0]\n",
    "    obj_value = 0.5 * lamb * (np.linalg.norm(w) **2) + np.sum(zmax) / N\n",
    "    #print(obj_value)\n",
    "\n",
    "    return obj_value\n",
    "\n",
    "\n",
    "###### Q1.2 ######\n",
    "def pegasos_train(Xtrain, ytrain, w, lamb, k, max_iterations):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    - Xtrain: A list of num_train elements, where each element is a list of D-dimensional features.\n",
    "    - ytrain: A list of num_train labels\n",
    "    - w: a numpy array of D elements as a D-dimension vector, which is the weight vector and initialized to be all 0s\n",
    "    - lamb: lambda used in pegasos algorithm\n",
    "    - k: mini-batch size\n",
    "    - max_iterations: the total number of iterations to update parameters\n",
    "\n",
    "    Returns:\n",
    "    - learnt w\n",
    "    - train_obj: a list of the objective function value at each iteration during the training process, length of 500.\n",
    "    \"\"\"\n",
    "    np.random.seed(0)\n",
    "    Xtrain = np.array(Xtrain)\n",
    "    ytrain = np.array(ytrain)\n",
    "    N = Xtrain.shape[0]\n",
    "    D = Xtrain.shape[1]\n",
    "\n",
    "    train_obj = []\n",
    "\n",
    "    for iter in range(1, max_iterations + 1):\n",
    "        A_t = np.floor(np.random.rand(k) * N).astype(int)  # index of the current mini-batch\n",
    "\n",
    "        # you need to fill in your solution here\n",
    "        X_t = Xtrain[A_t, :]\n",
    "        y_t = ytrain[A_t]\n",
    "        \n",
    "        # 4\n",
    "        #A_tpls = A_t[np.multiply(y_t, np.dot(X_t,w)) < 1]\n",
    "        A_tpls = A_t[(np.multiply(y_t, np.transpose(np.dot(X_t,w)) )<1).ravel()]\n",
    "        X_tpls = Xtrain[A_tpls, :]\n",
    "        y_tpls = ytrain[A_tpls]\n",
    "        \n",
    "        # 5\n",
    "        ita_t = 1/(lamb * iter)\n",
    "        \n",
    "        \n",
    "        # 6\n",
    "        w_thalf = (1 - (ita_t * lamb)) * w + ita_t * np.sum(\n",
    "            np.multiply(y_tpls.reshape(y_tpls.shape[0],1),X_tpls),\n",
    "            axis=0).reshape(D,1)/ k\n",
    "        \n",
    "        # 7\n",
    "        #w = w_thalf * min(1,1/(np.sqrt(lamb) * np.linalg.norm(np.array(w_thalf))))\n",
    "        w = w_thalf * min(1, 1 / np.sqrt(lamb) / np.linalg.norm(w_thalf))\n",
    "        \n",
    "        train_obj.append(objective_function(Xtrain, ytrain, w, lamb))\n",
    "        print(train_obj[iter-1])\n",
    "        # print(w[0])\n",
    "    \n",
    "\n",
    "    return w, train_obj\n",
    "\n",
    "\n",
    "###### Q1.3 ######\n",
    "def pegasos_test(Xtest, ytest, w_l):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    - Xtest: A list of num_test elements, where each element is a list of D-dimensional features.\n",
    "    - ytest: A list of num_test labels\n",
    "    - w_l: a numpy array of D elements as a D-dimension vector, which is the weight vector of SVM classifier and learned by pegasos_train()\n",
    " \n",
    "    Returns:\n",
    "    - test_acc: testing accuracy.\n",
    "    \"\"\"\n",
    "    # you need to fill in your solution here\n",
    "    Xtest = np.array(Xtest)\n",
    "    ytest = np.array(ytest)\n",
    "    N = Xtest.shape[0]\n",
    "    ywx = (np.multiply(ytest, np.transpose(np.dot(Xtest, w_l))) > 0).ravel()\n",
    "    ytru = ytest > 0\n",
    "    test_acc = sum(ytru == ywx)/N\n",
    "\n",
    "\n",
    "    return test_acc\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "NO MODIFICATIONS below this line.\n",
    "You should only write your code in the above functions.\n",
    "\"\"\"\n",
    "\n",
    "def data_loader_mnist(dataset):\n",
    "\n",
    "    with open(dataset, 'r') as f:\n",
    "            data_set = json.load(f)\n",
    "    train_set, valid_set, test_set = data_set['train'], data_set['valid'], data_set['test']\n",
    "\n",
    "    Xtrain = train_set[0]\n",
    "    ytrain = train_set[1]\n",
    "    Xvalid = valid_set[0]\n",
    "    yvalid = valid_set[1]\n",
    "    Xtest = test_set[0]\n",
    "    ytest = test_set[1]\n",
    "\n",
    "    ## below we add 'one' to the feature of each sample, such that we include the bias term into parameter w\n",
    "    Xtrain = np.hstack((np.ones((len(Xtrain), 1)), np.array(Xtrain))).tolist()\n",
    "    Xvalid = np.hstack((np.ones((len(Xvalid), 1)), np.array(Xvalid))).tolist()\n",
    "    Xtest = np.hstack((np.ones((len(Xtest), 1)), np.array(Xtest))).tolist()\n",
    "\n",
    "    for i, v in enumerate(ytrain):\n",
    "        if v < 5:\n",
    "            ytrain[i] = -1.\n",
    "        else:\n",
    "            ytrain[i] = 1.\n",
    "    for i, v in enumerate(ytest):\n",
    "        if v < 5:\n",
    "            ytest[i] = -1.\n",
    "        else:\n",
    "            ytest[i] = 1.\n",
    "\n",
    "    return Xtrain, ytrain, Xvalid, yvalid, Xtest, ytest\n",
    "\n",
    "\n",
    "def pegasos_mnist():\n",
    "\n",
    "    test_acc = {}\n",
    "    train_obj = {}\n",
    "\n",
    "    Xtrain, ytrain, Xvalid, yvalid, Xtest, ytest = data_loader_mnist(dataset = 'mnist_subset.json')\n",
    "\n",
    "    max_iterations = 500\n",
    "    k = 100\n",
    "    for lamb in (0.01, 0.1, 1):\n",
    "        w = np.zeros((len(Xtrain[0]), 1))\n",
    "        w_l, train_obj['k=' + str(k) + '_lambda=' + str(lamb)] = pegasos_train(Xtrain, ytrain, w, lamb, k, max_iterations)\n",
    "        test_acc['k=' + str(k) + '_lambda=' + str(lamb)] = pegasos_test(Xtest, ytest, w_l)\n",
    "\n",
    "    lamb = 0.1\n",
    "    for k in (1, 10, 1000):\n",
    "        w = np.zeros((len(Xtrain[0]), 1))\n",
    "        w_l, train_obj['k=' + str(k) + '_lambda=' + str(lamb)] = pegasos_train(Xtrain, ytrain, w, lamb, k, max_iterations)\n",
    "        test_acc['k=' + str(k) + '_lambda=' + str(lamb)] = pegasos_test(Xtest, ytest, w_l)\n",
    "\n",
    "    return test_acc, train_obj\n",
    "\n",
    "\n",
    "def main():\n",
    "    test_acc, train_obj = pegasos_mnist() # results on mnist\n",
    "    print('mnist test acc \\n')\n",
    "    for key, value in test_acc.items():\n",
    "        print('%s: test acc = %.4f \\n' % (key, value))\n",
    "\n",
    "    #with open('pegasos.json', 'w') as f_json:\n",
    "    #    json.dump([test_acc, train_obj], f_json)\n",
    "\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "#    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, ytrain, Xvalid, yvalid, Xtest, ytest = data_loader_mnist(dataset = 'mnist_subset.json')\n",
    "X = np.array(Xtrain)\n",
    "y = np.array(ytrain)\n",
    "N = X.shape[0]\n",
    "D = X.shape[1]\n",
    "w = np.ones((D,1))\n",
    "lamb = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # 0.5 * lamb * ||w||^2 + 1/N sum(max(0,1-ywx)) \n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    D = X.shape[1]\n",
    "    z = 1- np.multiply(y, np.transpose(np.dot(X,w)))\n",
    "    zmax = z[z>0]\n",
    "    obj_value = 0.5 * lamb * (np.linalg.norm(w) **2 ) + np.sum(zmax) / N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1000\n",
    "max_iterations = 500\n",
    "w = np.zeros((D,1))\n",
    "lamb = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1978935826183894\n",
      "2.5986170484507527\n",
      "1.1825609547621951\n",
      "0.9932504435632661\n",
      "0.9592003990864778\n",
      "0.8187052558369847\n",
      "0.8097625898278371\n",
      "0.8010816810864815\n",
      "0.7829535395765986\n",
      "0.781311315656391\n",
      "0.7691192109460383\n",
      "0.7628782122913011\n",
      "0.7435238241814282\n",
      "0.7234428346490597\n",
      "0.7062363141156179\n",
      "0.6854604292009946\n",
      "0.6758281526841875\n",
      "0.6602699469111746\n",
      "0.6595622785938285\n",
      "0.6524523060937539\n",
      "0.6508762024722986\n",
      "0.6446479254037688\n",
      "0.6398209337501717\n",
      "0.640015323265747\n",
      "0.6365638041682576\n",
      "0.6356423802581562\n",
      "0.6369575486018091\n",
      "0.6368435318662853\n",
      "0.6353777136210814\n"
     ]
    }
   ],
   "source": [
    "    \"\"\"\n",
    "    Inputs:\n",
    "    - Xtrain: A list of num_train elements, where each element is a list of D-dimensional features.\n",
    "    - ytrain: A list of num_train labels\n",
    "    - w: a numpy array of D elements as a D-dimension vector, which is the weight vector and initialized to be all 0s\n",
    "    - lamb: lambda used in pegasos algorithm\n",
    "    - k: mini-batch size\n",
    "    - max_iterations: the total number of iterations to update parameters\n",
    "\n",
    "    Returns:\n",
    "    - learnt w\n",
    "    - train_obj: a list of the objective function value at each iteration during the training process, length of 500.\n",
    "    \"\"\"\n",
    "    np.random.seed(0)\n",
    "    Xtrain = np.array(Xtrain)\n",
    "    ytrain = np.array(ytrain)\n",
    "    N = Xtrain.shape[0]\n",
    "    D = Xtrain.shape[1]\n",
    "\n",
    "    train_obj = []\n",
    "\n",
    "#    for iter in range(1, max_iterations + 1):\n",
    "    for iter in range(1,30):\n",
    "        A_t = np.floor(np.random.rand(k) * N).astype(int)  # index of the current mini-batch\n",
    "\n",
    "        # you need to fill in your solution here\n",
    "        X_t = Xtrain[A_t, :]\n",
    "        y_t = ytrain[A_t].astype(int)\n",
    "        \n",
    "        # 4\n",
    "        A_tpls = A_t[(np.multiply(y_t, np.transpose(np.dot(X_t, w)))<1).ravel()]\n",
    "        X_tpls = Xtrain[A_tpls, :]\n",
    "        y_tpls = ytrain[A_tpls].astype(int)\n",
    "        #print('min', min(y_tpls))\n",
    "        #print('max', max(y_tpls))\n",
    "        \n",
    "        # 5\n",
    "        ita_t = 1/(lamb * iter)\n",
    "        #print(ita_t)\n",
    "        \n",
    "        # 6\n",
    "        w_thalf = (1-ita_t * lamb) * w + (ita_t / k) * np.sum(\n",
    "            np.multiply(y_tpls.reshape(y_tpls.shape[0], 1), X_tpls),\n",
    "            axis=0).reshape(D,1)\n",
    "        \n",
    "        # 7\n",
    "        #w = w_thalf * min(1,1/(np.sqrt(lamb) * np.linalg.norm(np.array(w_thalf))))\n",
    "        w_ = w\n",
    "        print(np.linalg.norm(w_thalf))\n",
    "        w = w_thalf * min(1, 1/(np.sqrt(lamb) * np.linalg.norm(w_thalf)))\n",
    "\n",
    "        train_obj.append(objective_function(X_t, y_t, w, lamb))\n",
    "        #print(train_obj[iter-1])\n",
    "        \n",
    "    #print(train_obj)\n",
    "\n",
    "\n",
    "    #return w, train_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### line 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2716, 1980,  929, 3041,  557, 4739, 2351, 4039,   99, 2166])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_t[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2716, 1980,  929,  557, 4739, 2351, 4039,   99, 2166, 4460])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_tpls[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.1171875  0.5625     0.8125     0.99609375\n",
      " 0.95703125 0.5703125  0.5703125  0.0859375  0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.265625\n",
      " 0.92578125 0.98828125 0.98828125 0.98828125 0.98828125 0.98828125\n",
      " 0.98828125 0.5859375  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.23828125 0.94140625 0.98828125 0.98828125\n",
      " 0.9765625  0.81640625 0.765625   0.98828125 0.98828125 0.8828125\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.0546875\n",
      " 0.90625    0.98828125 0.98828125 0.80859375 0.14453125 0.\n",
      " 0.0703125  0.93359375 0.98828125 0.8828125  0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.3203125  0.98828125 0.98828125\n",
      " 0.8828125  0.05859375 0.         0.         0.         0.65625\n",
      " 0.98828125 0.75       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.3203125  0.98828125 0.98828125 0.80859375 0.0390625\n",
      " 0.         0.         0.078125   0.95703125 0.98828125 0.46484375\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.3203125\n",
      " 0.98828125 0.98828125 0.98828125 0.08203125 0.         0.\n",
      " 0.4296875  0.98828125 0.98828125 0.203125   0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.07421875 0.765625   0.98828125\n",
      " 0.98828125 0.75390625 0.125      0.27734375 0.9765625  0.98828125\n",
      " 0.6953125  0.01171875 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.23828125 0.77734375 0.98828125 0.98828125\n",
      " 0.9375     0.9375     0.98828125 0.9765625  0.2109375  0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.0703125  0.75390625 0.98828125 0.98828125 0.98828125\n",
      " 0.98828125 0.66796875 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.07421875 0.7734375  0.98828125 0.98828125 0.98828125 0.3359375\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.5234375\n",
      " 0.98828125 0.98828125 0.98828125 0.8515625  0.09765625 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.91015625 0.98828125 0.98828125\n",
      " 0.98828125 0.98828125 0.1875     0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.27734375 0.9765625  0.98828125 0.828125   0.98828125 0.98828125\n",
      " 0.52734375 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.74609375 0.98828125\n",
      " 0.875      0.11328125 0.93359375 0.98828125 0.8125     0.0234375\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.76171875 0.98828125 0.4921875  0.\n",
      " 0.9296875  0.98828125 0.98828125 0.0390625  0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.76171875 0.98828125 0.79296875 0.38671875 0.98046875 0.98828125\n",
      " 0.98828125 0.0390625  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.3046875  0.98046875\n",
      " 0.98828125 0.984375   0.98828125 0.98828125 0.5625     0.00390625\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.49609375 0.98828125 0.98828125\n",
      " 0.98828125 0.98828125 0.1875     0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.01171875 0.41796875 0.74609375 0.56640625 0.46875\n",
      " 0.02734375 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.        ]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain[2176,:])\n",
    "print(ytrain[2176])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.63172475])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.multiply(ytrain[2176], np.transpose(np.dot(Xtrain[2176,:], w_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.3147609])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.multiply(ytrain[3041], np.transpose(np.dot(Xtrain[3041,:], w_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6611226985854638"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(w_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(735, 1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(X_tpls, w_).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(735, 1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tpls.reshape(y_tpls.shape[0], 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0    -1]\n",
      " [   -2    -3]\n",
      " [    4     5]\n",
      " ...\n",
      " [-1464 -1465]\n",
      " [-1466 -1467]\n",
      " [ 1468  1469]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array(range(X_tpls.shape[0]*2)).reshape((X_tpls.shape[0],2))\n",
    "print(np.multiply(y_tpls.reshape(y_tpls.shape[0], 1) ,a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22438, 22467])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum( np.multiply(y_tpls.reshape(y_tpls.shape[0], 1) ,a), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### line 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/lamb/iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/(lamb * iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### line 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.998"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-ita_t * lamb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.998"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - (ita_t * lamb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(785, 1)\n",
      "[[0.01638692]\n",
      " [0.02061471]\n",
      " [0.02567001]\n",
      " [0.0257776 ]\n",
      " [0.02368338]]\n"
     ]
    }
   ],
   "source": [
    "print(((1-ita_t * lamb) * w_).shape)\n",
    "print(((1-ita_t * lamb) * w_)[100:105])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4e-06"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ita_t / k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(785, 1)\n",
      "[[14.24609375]\n",
      " [16.66796875]\n",
      " [15.91796875]\n",
      " [15.1953125 ]\n",
      " [11.6875    ]]\n"
     ]
    }
   ],
   "source": [
    "print((np.sum(np.multiply(y_tpls.reshape(y_tpls.shape[0], 1), X_tpls),\n",
    "            axis=0).reshape(D,1)).shape)\n",
    "print((np.sum(np.multiply(y_tpls.reshape(y_tpls.shape[0], 1), X_tpls),\n",
    "            axis=0).reshape(D,1))[100:105])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00098249],\n",
       "       [0.00114952],\n",
       "       [0.00109779],\n",
       "       [0.00104795],\n",
       "       [0.00080603]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((ita_t / k) * np.sum(np.multiply(y_tpls.reshape(y_tpls.shape[0], 1), X_tpls),\n",
    "            axis=0).reshape(D,1))[100:105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(785, 1)\n",
      "[[ 8.90234375]\n",
      " [13.3671875 ]\n",
      " [12.6484375 ]\n",
      " [16.43359375]\n",
      " [12.70703125]]\n"
     ]
    }
   ],
   "source": [
    "print((np.sum(np.multiply(y_t.reshape(y_t.shape[0], 1), X_t),\n",
    "            axis=0).reshape(D,1)).shape)\n",
    "print((np.sum(np.multiply(y_t.reshape(y_t.shape[0], 1), X_t),\n",
    "            axis=0).reshape(D,1))[100:105])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### line 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.414213562373095"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/np.sqrt(lamb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6421561248852019"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(w_thalf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2022892993910377"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1/np.sqrt(lamb)) / np.linalg.norm(w_thalf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2022892993910377"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/ (np.sqrt(lamb) * np.linalg.norm(w_thalf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(1, (1/np.sqrt(lamb)) / np.linalg.norm(w_thalf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01679521]\n",
      " [0.02267094]\n",
      " [0.02501692]\n",
      " [0.02257767]\n",
      " [0.01720586]]\n",
      "[[0.01679521]\n",
      " [0.02267094]\n",
      " [0.02501692]\n",
      " [0.02257767]\n",
      " [0.01720586]]\n"
     ]
    }
   ],
   "source": [
    "print(w[100:105])\n",
    "print((min(1, (1/np.sqrt(lamb)) / np.linalg.norm(w_thalf)) * w_thalf)[100:105])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    max_iterations = 500\n",
    "    k = 100\n",
    "    lamb = 0.1\n",
    "    w = np.zeros((len(Xtrain[0]), 1))\n",
    "    w_l, train_obj= pegasos_train(Xtrain, ytrain, w, lamb, k, max_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"\"\"\n",
    "    Inputs:\n",
    "    - Xtest: A list of num_test elements, where each element is a list of D-dimensional features.\n",
    "    - ytest: A list of num_test labels\n",
    "    - w_l: a numpy array of D elements as a D-dimension vector, which is the weight vector of SVM classifier and learned by pegasos_train()\n",
    " \n",
    "    Returns:\n",
    "    - test_acc: testing accuracy.\n",
    "    \"\"\"\n",
    "    # you need to fill in your solution here\n",
    "    Xtest = np.array(Xtest)\n",
    "    ytest = np.array(ytest)\n",
    "    N = Xtest.shape[0]\n",
    "    #ywx = (np.multiply(ytest, np.transpose(np.dot(Xtest,w_l))) > 0).ravel()\n",
    "    ywx = np.sign((np.multiply(ytest, np.transpose(np.dot(Xtest,w_l)))).ravel())\n",
    "    #ytru = ytest > 0\n",
    "    #test_acc = sum(ytru == ywx)/N\n",
    "    test_acc = sum(ytest == ywx)/N\n",
    "\n",
    "\n",
    "    #return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.multiply(ytest, np.transpose(np.dot(Xtest,w_l))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ywx = (np.multiply(ytest, np.transpose(np.dot(Xtest,w_l))) > 0).ravel()\n",
    "ytru = ytest > 0\n",
    "sum(ytru * 1 == ywx * 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytru*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yytr=[True, True, False, False]\n",
    "yyte=[True, False, False, False]\n",
    "type(yyte)\n",
    "#sum(yytr == yyte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= np.array([1,2]) > 1\n",
    "b = np.array([[-1],[2]])>0\n",
    "a==b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a==np.transpose(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ywx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = np.array([[1,1],[1,0],[0,1],[-1,-1]])\n",
    "wg = np.array([[2],[4]])\n",
    "np.dot(g,wg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
