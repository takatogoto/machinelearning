{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation accuracy is 0.939 when k = 5\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Do not change the input and output format.\n",
    "If our script cannot run your code or the format is improper, your code will not be graded.\n",
    "\n",
    "The only functions you need to implement in this template is compute_distances, predict_labels, compute_accuracy\n",
    "and find_best_k.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "###### Q5.1 ######\n",
    "def compute_distances(Xtrain, X):\n",
    "    \"\"\"\"\n",
    "    Compute the distance between each test point in X and each training point\n",
    "    in Xtrain.\n",
    "    Inputs:\n",
    "    - Xtrain: A numpy array of shape (num_train, D) containing training data\n",
    "    - X: A numpy array of shape (num_test, D) containing test data.\n",
    "    Returns:\n",
    "    - dists: A numpy array of shape (num_test, num_train) where dists[i, j]\n",
    "      is the Euclidean distance between the ith test point and the jth training\n",
    "      point.\n",
    "    \"\"\"\n",
    "    #####################################################\n",
    "    #\n",
    "    # initialize array\n",
    "    dists = np.zeros([X.shape[0], Xtrain.shape[0]])\n",
    "    \n",
    "    # calculate distance as l2 norm\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(Xtrain.shape[0]):\n",
    "            dists[i,j] = np.linalg.norm(X[i,:] - Xtrain[j,:],2)\n",
    "    ##################################################### \n",
    "    return dists\n",
    "\n",
    "###### Q5.2 ######\n",
    "def predict_labels(k, ytrain, dists):\n",
    "    \"\"\"\n",
    "    Given a matrix of distances between test points and training points,\n",
    "    predict a label for each test point.\n",
    "    Inputs:\n",
    "    - k: The number of nearest neighbors used for prediction.\n",
    "    - ytrain: A numpy array of shape (num_train,) where ytrain[i] is the label\n",
    "      of the ith training point.\n",
    "    - dists: A numpy array of shape (num_test, num_train) where dists[i, j]\n",
    "      gives the distance betwen the ith test point and the jth training point.\n",
    "    Returns:\n",
    "    - ypred: A numpy array of shape (num_test,) containing predicted labels for the\n",
    "      test data, where y[i] is the predicted label for the test point X[i]. \n",
    "    \"\"\"\n",
    "    #####################################################\n",
    "    #\n",
    "    # number of class\n",
    "    c = 10\n",
    "    \n",
    "    # initialize array\n",
    "    vc = np.zeros([dists.shape[0], c], dtype=int) # voting result for each data\n",
    "    ypred = -np.ones([dists.shape[0]], dtype=int)\n",
    "    \n",
    "    # index of distance from the smallest to kth smallest for each data\n",
    "    # array(num_train, k)\n",
    "    knnind = np.argpartition(dists, k, axis = 1)[:,:k]\n",
    "    \n",
    "    # check for all num_train \n",
    "    for i in range(dists.shape[0]):\n",
    "        # extract k-nearest neighbor in ith train data\n",
    "        nny = ytrain[knnind[i,:]]\n",
    "        \n",
    "        # for all number of class\n",
    "        for j in range(c):\n",
    "            vc[i,j] = np.sum(nny == j)\n",
    "        \n",
    "        # argmax return the label with the smallest index\n",
    "        ypred[i] = vc[i,:].argmax()\n",
    "    #####################################################\n",
    "    return ypred\n",
    "\n",
    "###### Q5.3 ######\n",
    "def compute_accuracy(y, ypred):\n",
    "    \"\"\"\n",
    "    Compute the accuracy of prediction based on the true labels.\n",
    "    Inputs:\n",
    "    - y: A numpy array with of shape (num_test,) where y[i] is the true label\n",
    "      of the ith test point.\n",
    "    - ypred: A numpy array with of shape (num_test,) where ypred[i] is the \n",
    "      prediction of the ith test point.\n",
    "    Returns:\n",
    "    - acc: The accuracy of prediction (scalar).\n",
    "    \"\"\"\n",
    "    #####################################################\n",
    "    acc = sum(y == ypred)/len(y)\n",
    "    #####################################################\n",
    "    return acc\n",
    "\n",
    "###### Q5.4 ######\n",
    "def find_best_k(K, ytrain, dists, yval):\n",
    "    \"\"\"\n",
    "    Find best k according to validation accuracy.\n",
    "    Inputs:\n",
    "    - K: A list of ks.\n",
    "    - ytrain: A numpy array of shape (num_train,) where ytrain[i] is the label\n",
    "      of the ith training point.\n",
    "    - dists: A numpy array of shape (num_test, num_train) where dists[i, j]\n",
    "      is the Euclidean distance between the ith test point and the jth training\n",
    "      point.\n",
    "    - yval: A numpy array with of shape (num_val,) where y[i] is the true label\n",
    "      of the ith validation point.\n",
    "    Returns:\n",
    "    - best_k: The k with the highest validation accuracy.\n",
    "    - validation_accuracy: A list of accuracies of different ks in K.\n",
    "    \"\"\"\n",
    "    \n",
    "    #####################################################\n",
    "    #\n",
    "    # initialize array\n",
    "    all_acc = np.zeros([len(K)])\n",
    "    all_ypred = -np.ones([len(K), len(yval)])\n",
    "    i = 0\n",
    "    \n",
    "    for k in K:\n",
    "        all_ypred[i,:] = predict_labels(k, ytrain, dists)\n",
    "        all_acc[i] = compute_accuracy(yval, all_ypred[i,:])\n",
    "        i += 1\n",
    "    best_k = K[np.argmax(all_acc)]\n",
    "    validation_accuracy = all_acc.tolist()    \n",
    "    #####################################################\n",
    "    return best_k, validation_accuracy\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "NO MODIFICATIONS below this line.\n",
    "You should only write your code in the above functions.\n",
    "\"\"\"\n",
    "\n",
    "def data_processing(data):\n",
    "    train_set, valid_set, test_set = data['train'], data['valid'], data['test']\n",
    "    Xtrain = train_set[0]\n",
    "    ytrain = train_set[1]\n",
    "    Xval = valid_set[0]\n",
    "    yval = valid_set[1]\n",
    "    Xtest = test_set[0]\n",
    "    ytest = test_set[1]\n",
    "    \n",
    "    Xtrain = np.array(Xtrain)\n",
    "    Xval = np.array(Xval)\n",
    "    Xtest = np.array(Xtest)\n",
    "    \n",
    "    ytrain = np.array(ytrain)\n",
    "    yval = np.array(yval)\n",
    "    ytest = np.array(ytest)\n",
    "    \n",
    "    return Xtrain, ytrain, Xval, yval, Xtest, ytest\n",
    "    \n",
    "def main():\n",
    "    input_file = 'mnist_subset.json'\n",
    "    output_file = 'knn_output.txt'\n",
    "\n",
    "    with open(input_file) as json_data:\n",
    "        data = json.load(json_data)\n",
    "    \n",
    "    #==================Compute distance matrix=======================\n",
    "    K=[1, 3, 5, 7, 9]    \n",
    "    \n",
    "    Xtrain, ytrain, Xval, yval, Xtest, ytest = data_processing(data)\n",
    "    \n",
    "    dists = compute_distances(Xtrain, Xval)\n",
    "    \n",
    "    #===============Compute validation accuracy when k=5=============\n",
    "    k = 5\n",
    "    ypred = predict_labels(k, ytrain, dists)\n",
    "    acc = compute_accuracy(yval, ypred)\n",
    "    print(\"The validation accuracy is\", acc, \"when k =\", k)\n",
    "    \n",
    "    #==========select the best k by using validation set==============\n",
    "    best_k,validation_accuracy = find_best_k(K, ytrain, dists, yval)\n",
    "\n",
    "    \n",
    "    #===============test the performance with your best k=============\n",
    "    dists = compute_distances(Xtrain, Xtest)\n",
    "    ypred = predict_labels(best_k, ytrain, dists)\n",
    "    test_accuracy = compute_accuracy(ytest, ypred)\n",
    "    \n",
    "    #====================write your results to file===================\n",
    "    f=open(output_file, 'w')\n",
    "    for i in range(len(K)):\n",
    "        f.write('%d %.3f' % (K[i], validation_accuracy[i])+'\\n')\n",
    "    f.write('%s %.3f' % ('test', test_accuracy))\n",
    "    f.close()\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tinput_file = 'mnist_subset.json'\n",
    "\toutput_file = 'knn_output.txt'\n",
    "\n",
    "\twith open(input_file) as json_data:\n",
    "\t\tdata = json.load(json_data)\n",
    "\t\n",
    "\t#==================Compute distance matrix=======================\n",
    "\tK=[1, 3, 5, 7, 9]\t\n",
    "\t\n",
    "\tXtrain, ytrain, Xval, yval, Xtest, ytest = data_processing(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.5859375 , 0.99609375, 0.7890625 ,\n",
       "       0.37890625, 0.09765625, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.1796875 ,\n",
       "       0.87109375, 0.3984375 , 0.7265625 , 0.98828125, 0.8203125 ,\n",
       "       0.16796875, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.15234375, 0.3125    , 0.        ,\n",
       "       0.01953125, 0.3203125 , 0.83203125, 0.92578125, 0.3515625 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.0546875 , 0.76171875, 0.9765625 , 0.3515625 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.05859375,\n",
       "       0.86328125, 0.74609375, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.58984375, 0.890625  ,\n",
       "       0.015625  , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.65234375, 0.98828125, 0.02734375, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.3671875 , 0.984375  ,\n",
       "       0.51953125, 0.00390625, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.25390625, 0.94140625, 0.65625   , 0.0234375 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.31640625, 0.9453125 , 0.515625  ,\n",
       "       0.02734375, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.25390625,\n",
       "       0.9453125 , 0.48828125, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.2265625 , 0.9296875 , 0.42578125, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.00390625, 0.24609375, 0.90234375,\n",
       "       0.3515625 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.4765625 , 0.98828125, 0.4140625 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.0703125 , 0.69921875, 0.97265625, 0.421875  ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.03515625, 0.73828125,\n",
       "       0.98046875, 0.5       , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.0703125 , 0.73828125, 0.9296875 , 0.33984375, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.03515625, 0.85546875, 0.921875  ,\n",
       "       0.28125   , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.00390625,\n",
       "       0.7109375 , 0.91796875, 0.21484375, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.0234375 , 0.8671875 , 0.2109375 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm([3,4],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.912333933724785"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(Xtrain[0,:] - Xtest[0,:],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Xtest.copy()\n",
    "dists = np.zeros([X.shape[0], Xtrain.shape[0]])\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    for j in range(Xtrain.shape[0]):\n",
    "        dists[i,j] = np.linalg.norm(X[i,:] - Xtrain[j,:],2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.91233393, 10.29929019, 10.68818172, ..., 12.80331941,\n",
       "         8.72943314, 10.37099002],\n",
       "       [10.49087055, 11.80837537, 11.65408461, ..., 10.06020011,\n",
       "        10.96881608, 10.47685889],\n",
       "       [10.05031592, 11.73988849, 11.77566323, ..., 13.34624377,\n",
       "        10.89469162, 11.0938449 ],\n",
       "       ...,\n",
       "       [11.22512985, 11.17216728, 11.78412041, ..., 12.77755811,\n",
       "        11.10235142,  8.38955017],\n",
       "       [ 9.64048651, 10.26215442, 12.267522  , ..., 12.95168953,\n",
       "        10.67060025, 10.17638254],\n",
       "       [ 9.10985071,  8.91970099, 10.70961468, ..., 13.41502253,\n",
       "        10.28604116, 10.39319312]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 5000)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 784)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 5 4 7 6 3 0 8 2 1]\n",
      "[6 9 8]\n"
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "a = np.arange(10)\n",
    "np.random.shuffle(a)\n",
    "print(a)\n",
    "ind = np.argpartition(a, k)[:k]\n",
    "ind = ind[np.argsort(a[ind])]\n",
    "print(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 0 9 8 2]\n",
      " [1 3 6 7 5]]\n",
      "[1 4 0]\n"
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "a = np.arange(10)\n",
    "np.random.shuffle(a)\n",
    "b = a.reshape(2,5)\n",
    "print(b)\n",
    "ind = np.argpartition(b, k, axis = 1)[:,:k]\n",
    "print(ind[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 6, 4, ..., 0, 9, 8])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "    c = 10 # number of class\n",
    "    #vc = np.zeros(dists.shape[0],c)\n",
    "    \n",
    "    # index of distance from smallest to kth \n",
    "    knnind = np.argpartition(dists, k, axis = 1)[:,:k]\n",
    "    i =0\n",
    "    #for i in range(dists.shape[0]):\n",
    "    nny = ytrain[knnind[i,:]]\n",
    "    vc = np.sum(nny == 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 9, 8])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.91233393, 10.29929019, 10.68818172, ..., 12.80331941,\n",
       "         8.72943314, 10.37099002],\n",
       "       [10.49087055, 11.80837537, 11.65408461, ..., 10.06020011,\n",
       "        10.96881608, 10.47685889],\n",
       "       [10.05031592, 11.73988849, 11.77566323, ..., 13.34624377,\n",
       "        10.89469162, 11.0938449 ],\n",
       "       ...,\n",
       "       [11.22512985, 11.17216728, 11.78412041, ..., 12.77755811,\n",
       "        11.10235142,  8.38955017],\n",
       "       [ 9.64048651, 10.26215442, 12.267522  , ..., 12.95168953,\n",
       "        10.67060025, 10.17638254],\n",
       "       [ 9.10985071,  8.91970099, 10.70961468, ..., 13.41502253,\n",
       "        10.28604116, 10.39319312]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "    c = 10 # number of class\n",
    "    vc = np.zeros([dists.shape[0], c], dtype=int)\n",
    "    ypred = -np.ones([dists.shape[0]], dtype=int)\n",
    "    \n",
    "    # index of distance from smallest to kth \n",
    "    knnind = np.argpartition(dists, k, axis = 1)[:,:k]\n",
    "    for i in range(dists.shape[0]):\n",
    "        nny = ytrain[knnind[i,:]]\n",
    "        for j in range(c):\n",
    "            vc[i,j] = np.sum(nny ==j)\n",
    "        ypred[i] = vc[i,:].argmax()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 0, 3, 9, 3, 3, 3, 6, 9, 3, 0, 0, 3, 9, 4, 5, 0, 3, 8, 8, 1, 3,\n",
       "       8, 1, 0, 4, 9, 0, 8, 0, 1, 4, 8, 7, 8, 2, 1, 3, 9, 5, 9, 4, 3, 6,\n",
       "       0, 6, 7, 4, 3, 3, 3, 6, 3, 5, 3, 6, 3, 3, 0, 8, 7, 9, 6, 0, 6, 1,\n",
       "       8, 9, 1, 1, 5, 6, 2, 1, 9, 5, 7, 4, 7, 7, 0, 2, 1, 4, 1, 4, 4, 9,\n",
       "       0, 1, 8, 3, 9, 8, 7, 1, 1, 8, 1, 9, 8, 6, 2, 5, 8, 1, 3, 9, 8, 1,\n",
       "       1, 5, 6, 3, 6, 4, 8, 3, 1, 6, 8, 7, 5, 5, 2, 1, 0, 8, 6, 7, 4, 3,\n",
       "       9, 3, 1, 3, 2, 6, 8, 3, 4, 9, 3, 0, 2, 9, 9, 5, 6, 6, 7, 4, 4, 6,\n",
       "       8, 1, 1, 7, 0, 1, 1, 0, 7, 2, 0, 0, 6, 5, 2, 3, 4, 9, 4, 6, 7, 4,\n",
       "       4, 5, 6, 7, 0, 2, 1, 7, 4, 4, 6, 7, 4, 4, 7, 0, 4, 9, 5, 7, 1, 9,\n",
       "       3, 6, 4, 6, 1, 5, 5, 6, 1, 7, 9, 6, 5, 5, 1, 1, 2, 8, 5, 6, 2, 1,\n",
       "       0, 6, 0, 7, 6, 0, 6, 6, 3, 0, 7, 5, 9, 9, 2, 9, 1, 5, 5, 2, 1, 4,\n",
       "       9, 9, 6, 3, 6, 3, 0, 7, 0, 7, 5, 5, 7, 7, 9, 5, 6, 8, 9, 0, 5, 0,\n",
       "       4, 1, 5, 7, 9, 5, 1, 6, 3, 1, 8, 1, 9, 2, 9, 1, 8, 7, 1, 0, 4, 9,\n",
       "       9, 1, 3, 4, 1, 6, 3, 2, 3, 8, 3, 5, 2, 7, 7, 5, 0, 9, 1, 5, 1, 8,\n",
       "       3, 5, 1, 2, 6, 1, 6, 4, 1, 9, 8, 0, 4, 3, 8, 9, 3, 7, 5, 9, 1, 7,\n",
       "       2, 1, 3, 7, 1, 9, 7, 7, 2, 5, 5, 9, 5, 6, 5, 7, 2, 1, 7, 4, 8, 7,\n",
       "       1, 6, 1, 6, 7, 7, 9, 7, 0, 2, 9, 6, 2, 3, 4, 8, 6, 2, 1, 2, 2, 0,\n",
       "       5, 1, 6, 4, 9, 2, 7, 2, 8, 4, 2, 2, 2, 1, 1, 6, 0, 1, 2, 1, 8, 5,\n",
       "       2, 2, 6, 1, 0, 1, 0, 4, 3, 8, 6, 0, 4, 8, 7, 5, 6, 7, 4, 0, 0, 0,\n",
       "       8, 2, 2, 6, 2, 5, 5, 6, 2, 9, 3, 3, 8, 4, 6, 7, 7, 3, 1, 0, 9, 3,\n",
       "       7, 3, 5, 5, 9, 4, 7, 6, 0, 9, 8, 1, 4, 3, 5, 8, 4, 6, 6, 4, 6, 2,\n",
       "       0, 3, 1, 6, 1, 0, 7, 5, 1, 7, 3, 4, 9, 2, 2, 9, 4, 8, 9, 6, 3, 5,\n",
       "       7, 4, 1, 4, 7, 5, 9, 5, 0, 4, 1, 9, 6, 6, 8, 3, 3, 9, 9, 5, 0, 4,\n",
       "       0, 7, 4, 5, 2, 3, 2, 9, 4, 5, 8, 9, 2, 7, 9, 5, 0, 7, 2, 2, 0, 1,\n",
       "       9, 2, 0, 0, 1, 2, 6, 2, 0, 0, 1, 4, 5, 8, 7, 3, 3, 5, 5, 7, 4, 8,\n",
       "       5, 2, 3, 4, 3, 0, 2, 9, 9, 2, 8, 9, 4, 6, 0, 8, 6, 1, 9, 2, 2, 7,\n",
       "       0, 8, 2, 6, 2, 6, 8, 6, 1, 7, 8, 7, 3, 4, 7, 8, 8, 1, 6, 4, 5, 0,\n",
       "       6, 7, 5, 6, 8, 8, 9, 7, 3, 8, 0, 8, 0, 1, 0, 8, 4, 9, 2, 7, 1, 4,\n",
       "       4, 9, 8, 5, 9, 1, 4, 9, 4, 8, 6, 0, 0, 2, 3, 7, 7, 6, 7, 3, 4, 4,\n",
       "       6, 7, 6, 3, 1, 5, 7, 3, 2, 9, 9, 0, 8, 4, 3, 2, 8, 5, 1, 1, 9, 2,\n",
       "       1, 0, 4, 7, 7, 2, 8, 5, 4, 8, 9, 7, 1, 5, 5, 2, 9, 3, 9, 3, 7, 0,\n",
       "       9, 3, 8, 4, 2, 8, 2, 6, 6, 5, 1, 2, 8, 1, 4, 1, 6, 5, 1, 1, 5, 1,\n",
       "       4, 6, 0, 2, 9, 0, 3, 0, 0, 0, 0, 4, 8, 7, 8, 6, 1, 8, 6, 0, 5, 1,\n",
       "       8, 9, 3, 4, 0, 0, 6, 0, 2, 0, 7, 3, 4, 1, 5, 0, 5, 9, 1, 2, 2, 2,\n",
       "       3, 1, 3, 1, 4, 6, 0, 0, 4, 9, 5, 5, 0, 8, 7, 1, 4, 3, 6, 0, 8, 5,\n",
       "       7, 3, 8, 0, 0, 9, 6, 4, 2, 6, 7, 6, 5, 5, 5, 4, 0, 1, 0, 9, 4, 5,\n",
       "       2, 2, 7, 9, 0, 9, 5, 0, 3, 5, 5, 1, 5, 4, 8, 4, 2, 1, 6, 7, 0, 5,\n",
       "       0, 2, 9, 4, 7, 2, 1, 7, 7, 8, 2, 8, 5, 3, 9, 8, 6, 0, 4, 7, 1, 3,\n",
       "       5, 6, 3, 9, 7, 6, 6, 5, 3, 1, 7, 4, 1, 0, 7, 2, 0, 9, 9, 6, 1, 0,\n",
       "       4, 3, 3, 3, 0, 5, 6, 3, 3, 9, 6, 7, 3, 3, 0, 4, 7, 0, 3, 2, 8, 7,\n",
       "       8, 6, 2, 1, 5, 3, 6, 4, 6, 2, 8, 1, 8, 0, 1, 1, 8, 7, 5, 5, 3, 2,\n",
       "       1, 9, 5, 3, 4, 8, 6, 3, 5, 9, 3, 0, 6, 1, 2, 2, 9, 8, 5, 7, 2, 0,\n",
       "       4, 0, 7, 0, 3, 5, 8, 6, 4, 0, 0, 3, 9, 5, 8, 3, 1, 4, 2, 2, 2, 0,\n",
       "       6, 3, 2, 9, 7, 8, 3, 6, 9, 4, 0, 9, 2, 7, 0, 0, 2, 5, 6, 6, 5, 5,\n",
       "       3, 1, 4, 7, 9, 8, 3, 3, 3, 4, 7, 2, 1, 9, 0, 5, 4, 1, 6, 7, 6, 5,\n",
       "       9, 7, 4, 4, 2, 7, 9, 3, 5, 4])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,1,1,0])\n",
    "b = np.array([0,1,0,1])\n",
    "sum(a == b)/len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "    all_acc = np.zeros([len(K)])\n",
    "    all_ypred = -np.ones([len(K), len(yval)])\n",
    "    i = 0\n",
    "    for k in K:\n",
    "        all_ypred[i,:] = predict_labels(k, ytrain, dists)\n",
    "        all_acc[i] = compute_accuracy(yval, all_ypred[i,:])\n",
    "        i += 1\n",
    "    best_k = K[np.argmin(all_acc)]\n",
    "    validation_accuracy = all_acc.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.265, 0.262, 0.26 , 0.261, 0.262])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
